"""
æ™‚ç³»åˆ—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åŒ–åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Xï¼ˆTwitterï¼‰ãƒ‡ãƒ¼ã‚¿ã®æŠ•ç¨¿æ™‚åˆ»ã‚’é›†è¨ˆã—ã€ç‚ä¸Šåˆ†æã®å‰å‡¦ç†ã‚’è¡Œã†
"""

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from pathlib import Path
from datetime import datetime
import sys
import glob

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆmatplotlibç”¨ï¼‰
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False


def load_and_prepare_data(csv_path: str) -> pd.DataFrame:
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æº–å‚™ã™ã‚‹
    
    Args:
        csv_path: å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        pd.DataFrame: æ™‚ç³»åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã•ã‚ŒãŸDataFrame
        
    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        ValueError: æ—¥ä»˜å¤‰æ›ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
    if not Path(csv_path).exists():
        raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
    
    print(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {csv_path}")
    
    # CSVèª­ã¿è¾¼ã¿ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    try:
        df = pd.read_csv(csv_path, comment='#')
        print(f"âœ“ {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    except Exception as e:
        raise ValueError(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # åˆ—åã®ç¢ºèªã¨èª¿æ•´
    if 'created_at' in df.columns:
        date_column = 'created_at'
    elif 'date' in df.columns:
        date_column = 'date'
    else:
        raise ValueError("created_at ã¾ãŸã¯ date åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # æ—¥ä»˜åˆ—ã‚’datetimeå‹ã«å¤‰æ›
    try:
        df[date_column] = pd.to_datetime(df[date_column], utc=True)
        print(f"âœ“ æ—¥ä»˜åˆ— '{date_column}' ã‚’UTCæ™‚åˆ»ã«å¤‰æ›ã—ã¾ã—ãŸ")
    except Exception as e:
        raise ValueError(f"æ—¥ä»˜å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
    
    # NaTï¼ˆæ¬ æå€¤ï¼‰ã‚’é™¤å»
    before_count = len(df)
    df = df.dropna(subset=[date_column])
    after_count = len(df)
    if before_count > after_count:
        print(f"âš  æ—¥ä»˜ãŒæ¬ æã—ã¦ã„ã‚‹ {before_count - after_count}ä»¶ã‚’é™¤å¤–ã—ã¾ã—ãŸ")
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ—¥ä»˜åˆ—ã«è¨­å®š
    df = df.set_index(date_column)
    df = df.sort_index()
    
    print(f"âœ“ æœŸé–“: {df.index.min()} ï½ {df.index.max()}")
    
    return df


def resample_time_series(df: pd.DataFrame, window: str) -> pd.DataFrame:
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å¹…ã§æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚µãƒ³ãƒ—ãƒ«ã™ã‚‹
    
    Args:
        df: æ™‚ç³»åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã•ã‚ŒãŸDataFrame
        window: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å¹…ï¼ˆä¾‹: "1H", "30min", "10min"ï¼‰
        
    Returns:
        pd.DataFrame: ãƒªã‚µãƒ³ãƒ—ãƒ«ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼ˆæŠ•ç¨¿ä»¶æ•°ï¼‰
    """
    # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã”ã¨ã®æŠ•ç¨¿ä»¶æ•°ã‚’é›†è¨ˆ
    resampled = df.resample(window).size()
    
    # DataFrameã«å¤‰æ›
    result = pd.DataFrame({
        'timestamp': resampled.index,
        'count': resampled.values
    })
    
    return result


def save_time_series_data(df: pd.DataFrame, windows: dict, output_dir: str = "time_series_data", file_prefix: str = ""):
    """
    è¤‡æ•°ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å¹…ã§é›†è¨ˆã—ã€CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹
    
    Args:
        df: æ™‚ç³»åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã•ã‚ŒãŸDataFrame
        windows: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å¹…ã®è¾æ›¸ {ãƒ•ã‚¡ã‚¤ãƒ«åæ¥å°¾è¾: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å¹…}
        output_dir: å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        file_prefix: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆç©ºæ–‡å­—åˆ—ã®å ´åˆã¯ä»˜åŠ ã—ãªã„ï¼‰
    """
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    print(f"\nğŸ“Š æ™‚ç³»åˆ—é›†è¨ˆã‚’é–‹å§‹...")
    
    results = {}
    
    for suffix, window in windows.items():
        print(f"\nâ–¶ {window} ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§é›†è¨ˆä¸­...")
        
        # ãƒªã‚µãƒ³ãƒ—ãƒ«
        resampled = resample_time_series(df, window)
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        print(f"  - ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°: {len(resampled)}")
        print(f"  - å¹³å‡æŠ•ç¨¿ä»¶æ•°: {resampled['count'].mean():.2f}")
        print(f"  - æœ€å¤§æŠ•ç¨¿ä»¶æ•°: {resampled['count'].max()}")
        print(f"  - æœ€å°æŠ•ç¨¿ä»¶æ•°: {resampled['count'].min()}")
        
        # CSVä¿å­˜ï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒã‚ã‚‹å ´åˆã¯ä»˜åŠ ï¼‰
        if file_prefix:
            output_file = output_path / f"{file_prefix}_time_series_{suffix}.csv"
        else:
            output_file = output_path / f"time_series_{suffix}.csv"
        resampled.to_csv(output_file, index=False)
        print(f"  âœ“ ä¿å­˜å®Œäº†: {output_file}")
        
        results[suffix] = resampled
    
    return results


def plot_time_series(df: pd.DataFrame, output_dir: str = "time_series_data", file_prefix: str = ""):
    """
    1æ™‚é–“ã”ã¨ã®æŠ•ç¨¿ä»¶æ•°ã‚’ã‚°ãƒ©ãƒ•åŒ–ã™ã‚‹
    
    Args:
        df: æ™‚ç³»åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã•ã‚ŒãŸDataFrame
        output_dir: å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        file_prefix: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆç©ºæ–‡å­—åˆ—ã®å ´åˆã¯ä»˜åŠ ã—ãªã„ï¼‰
    """
    print(f"\nğŸ“ˆ ã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­...")
    
    # 1æ™‚é–“ã”ã¨ã«é›†è¨ˆ
    hourly = resample_time_series(df, "1H")
    
    # ã‚°ãƒ©ãƒ•ä½œæˆ
    fig, ax = plt.subplots(figsize=(14, 6))
    
    # æŠ•ç¨¿ä»¶æ•°ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    ax.plot(hourly['timestamp'], hourly['count'], 
            marker='o', markersize=4, linewidth=1.5, 
            color='#2E86AB', label='Posts per hour')
    
    # ã‚°ãƒªãƒƒãƒ‰
    ax.grid(True, alpha=0.3, linestyle='--')
    
    # ãƒ©ãƒ™ãƒ«è¨­å®š
    ax.set_xlabel('Date/Time (UTC)', fontsize=12, fontweight='bold')
    ax.set_ylabel('Number of Posts', fontsize=12, fontweight='bold')
    ax.set_title('Time Series Analysis: Posts per Hour', 
                 fontsize=14, fontweight='bold', pad=20)
    
    # Xè»¸ã®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))
    ax.xaxis.set_major_locator(mdates.HourLocator(interval=max(1, len(hourly) // 20)))
    plt.xticks(rotation=45, ha='right')
    
    # å‡¡ä¾‹
    ax.legend(loc='upper right', framealpha=0.9)
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
    plt.tight_layout()
    
    # ä¿å­˜ï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒã‚ã‚‹å ´åˆã¯ä»˜åŠ ï¼‰
    output_path = Path(output_dir)
    if file_prefix:
        output_file = output_path / f"{file_prefix}_time_series_plot.png"
    else:
        output_file = output_path / "time_series_plot.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"âœ“ ã‚°ãƒ©ãƒ•ä¿å­˜å®Œäº†: {output_file}")
    
    # è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    # plt.show()
    plt.close()


def extract_query_from_filename(csv_path: str) -> str:
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æŠ½å‡ºã™ã‚‹
    
    Args:
        csv_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        str: æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆæŠ½å‡ºã§ããªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
    """
    csv_filename = Path(csv_path).stem  # æ‹¡å¼µå­ãªã—ã®ãƒ•ã‚¡ã‚¤ãƒ«å
    
    if csv_filename.startswith("tweets_"):
        # "tweets_"ã‚’é™¤å»
        name_part = csv_filename[7:]
        # æ•°å­—ã®ã¿ã®éƒ¨åˆ†ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰ã‚’é™¤å»
        parts = name_part.split("_")
        query_parts = [p for p in parts if not p.isdigit()]
        return "_".join(query_parts) if query_parts else csv_filename
    else:
        return csv_filename


def process_single_file(csv_path: str, windows: dict, output_dir: str):
    """
    å˜ä¸€ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹
    
    Args:
        csv_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        windows: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å¹…ã®è¾æ›¸
        output_dir: å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æŠ½å‡º
    query = extract_query_from_filename(csv_path)
    
    print(f"\n{'='*60}")
    print(f"å‡¦ç†ä¸­: {Path(csv_path).name}")
    print(f"æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}")
    print(f"{'='*60}")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨æº–å‚™
    df = load_and_prepare_data(csv_path)
    
    # æ™‚ç³»åˆ—é›†è¨ˆã¨CSVä¿å­˜
    results = save_time_series_data(df, windows, output_dir, file_prefix=query)
    
    # ã‚°ãƒ©ãƒ•ç”Ÿæˆ
    plot_time_series(df, output_dir, file_prefix=query)


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    print("=" * 60)
    print("æ™‚ç³»åˆ—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åŒ–åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    
    # è¨­å®š===========================================================
    # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ: ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã‚„å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
    INPUT_PATTERNS = [
        "original_data/tweets_*.csv",  # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æŒ‡å®š
        # "original_data/tweets_æ¾æœ¬äººå¿—_20251112_093317.csv",  # å€‹åˆ¥æŒ‡å®šã‚‚å¯èƒ½
    ]
    OUTPUT_DIR = "time_series_data"
    # ===============================================================
    
    # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å¹…ã®å®šç¾©
    WINDOWS = {
        "1h": "1H",      # 1æ™‚é–“
        "30m": "30min",  # 30åˆ†
        "10m": "10min"   # 10åˆ†
    }
    
    try:
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
        csv_files = []
        for pattern in INPUT_PATTERNS:
            if '*' in pattern or '?' in pattern:
                # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã®å ´åˆ
                matched_files = glob.glob(pattern)
                csv_files.extend(matched_files)
            else:
                # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                csv_files.append(pattern)
        
        # é‡è¤‡ã‚’é™¤å»ã—ã¦ã‚½ãƒ¼ãƒˆ
        csv_files = sorted(set(csv_files))
        
        if not csv_files:
            print("\nâš  å‡¦ç†å¯¾è±¡ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            print(f"ãƒ‘ã‚¿ãƒ¼ãƒ³: {INPUT_PATTERNS}")
            sys.exit(0)
        
        print(f"\nğŸ“‹ å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(csv_files)}")
        for i, f in enumerate(csv_files, 1):
            print(f"  {i}. {f}")
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
        success_count = 0
        error_count = 0
        
        for csv_file in csv_files:
            try:
                process_single_file(csv_file, WINDOWS, OUTPUT_DIR)
                success_count += 1
            except Exception as e:
                error_count += 1
                print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ ({Path(csv_file).name}): {e}")
                continue
        
        print("\n" + "=" * 60)
        print(f"âœ… å‡¦ç†å®Œäº†: æˆåŠŸ {success_count}ä»¶ / ã‚¨ãƒ©ãƒ¼ {error_count}ä»¶")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
