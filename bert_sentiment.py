#!/usr/bin/env python3
"""
æ—¥æœ¬èªBERTã«ã‚ˆã‚‹æ„Ÿæƒ…åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
HuggingFace ã® daigo/bert-base-japanese-sentiment ã‚’ä½¿ç”¨ã—ã¦ãƒ„ã‚¤ãƒ¼ãƒˆã‚’åˆ†æã™ã‚‹
"""

import sys
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from pathlib import Path
from tqdm import tqdm
import warnings

warnings.filterwarnings('ignore')


def load_model():
    """
    BERTãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
    GPU ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯è‡ªå‹•çš„ã«ä½¿ç”¨ã™ã‚‹
    
    Returns:
        tuple: (tokenizer, model, device)
    """
    # æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ï¼ˆæ±åŒ—å¤§å­¦ï¼‰+ æ„Ÿæƒ…åˆ†æç”¨ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
    # æ³¨: å®Ÿéš›ã®æ„Ÿæƒ…åˆ†æã«ã¯å°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦
    # ã“ã“ã§ã¯ koheiduck/bert-japanese-finetuned-sentiment ã‚’ä½¿ç”¨
    model_name = "koheiduck/bert-japanese-finetuned-sentiment"
    
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­: {model_name}")
    
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        
        # GPUåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        model.eval()
        
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        print(f"âœ“ ãƒ‡ãƒã‚¤ã‚¹: {device}")
        
        return tokenizer, model, device
        
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


def preprocess_text(text):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
    
    Args:
        text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        str: å‰å‡¦ç†æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ
    """
    if pd.isna(text):
        return ""
    
    text = str(text).strip()
    
    # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«
    text = " ".join(text.split())
    
    return text


def analyze_with_bert(texts, tokenizer, model, device, batch_size=32, 
                      threshold_config=None):
    """
    BERTãƒ¢ãƒ‡ãƒ«ã§ãƒãƒƒãƒæ¨è«–ã‚’å®Ÿè¡Œ
    
    Args:
        texts: ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
        tokenizer: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
        model: BERTãƒ¢ãƒ‡ãƒ«
        device: ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹
        batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
        threshold_config: é–¾å€¤è¨­å®šã®è¾æ›¸ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            ä¾‹: {
                'negative_threshold': 0.5,  # ãƒã‚¬ãƒ†ã‚£ãƒ–ã¨åˆ¤å®šã™ã‚‹æœ€ä½ç¢ºç‡
                'positive_threshold': 0.5,  # ãƒã‚¸ãƒ†ã‚£ãƒ–ã¨åˆ¤å®šã™ã‚‹æœ€ä½ç¢ºç‡
                'use_threshold': True       # é–¾å€¤ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            }
        
    Returns:
        list: å„ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†æçµæœ [{"label": str, "positive": float, "neutral": float, "negative": float}, ...]
    """
    results = []
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤è¨­å®š
    if threshold_config is None:
        threshold_config = {
            'negative_threshold': 0.4,  # ã“ã®ç¢ºç‡ä»¥ä¸Šã§ãƒã‚¬ãƒ†ã‚£ãƒ–
            'positive_threshold': 0.4,  # ã“ã®ç¢ºç‡ä»¥ä¸Šã§ãƒã‚¸ãƒ†ã‚£ãƒ–
            'use_threshold': False      # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€å¤§ç¢ºç‡æ–¹å¼
        }
    
    # ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆãƒ¢ãƒ‡ãƒ«ä¾å­˜ï¼‰
    id2label = model.config.id2label
    
    # ãƒãƒƒãƒå‡¦ç†
    for i in tqdm(range(0, len(texts), batch_size), desc="ğŸ” æ„Ÿæƒ…åˆ†æä¸­"):
        batch_texts = texts[i:i + batch_size]
        
        # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
        inputs = tokenizer(
            batch_texts,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors="pt"
        )
        
        # ãƒ‡ãƒã‚¤ã‚¹ã«è»¢é€
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        # æ¨è«–
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            probs = torch.nn.functional.softmax(logits, dim=-1)
        
        # çµæœã‚’è§£æ
        for prob in probs:
            prob_dict = {id2label[i]: prob[i].item() for i in range(len(prob))}
            
            # ãƒ©ãƒ™ãƒ«æ±ºå®š
            if threshold_config['use_threshold']:
                # é–¾å€¤ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®š
                negative_prob = prob_dict.get('NEGATIVE', 0.0)
                positive_prob = prob_dict.get('POSITIVE', 0.0)
                
                if negative_prob >= threshold_config['negative_threshold']:
                    predicted_label = 'NEGATIVE'
                elif positive_prob >= threshold_config['positive_threshold']:
                    predicted_label = 'POSITIVE'
                else:
                    predicted_label = 'NEUTRAL'
            else:
                # æœ€å¤§ç¢ºç‡æ–¹å¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
                predicted_label = max(prob_dict, key=prob_dict.get)
            
            result = {
                "label": predicted_label,
                "positive": prob_dict.get("positive", 0.0),
                "neutral": prob_dict.get("neutral", 0.0),
                "negative": prob_dict.get("negative", 0.0)
            }
            results.append(result)
    
    return results


def process_dataframe(df, tokenizer, model, device, threshold_config=None):
    """
    DataFrameã«å¯¾ã—ã¦æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œ
    
    Args:
        df: å…¥åŠ›DataFrame
        tokenizer: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
        model: BERTãƒ¢ãƒ‡ãƒ«
        device: ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹
        threshold_config: é–¾å€¤è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
    Returns:
        pd.DataFrame: æ„Ÿæƒ…åˆ†æçµæœãŒè¿½åŠ ã•ã‚ŒãŸDataFrame
    """
    # ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã®ç‰¹å®š
    if "content" in df.columns:
        text_column = "content"
    elif "text" in df.columns:
        text_column = "text"
    else:
        raise ValueError("âŒ 'content' ã¾ãŸã¯ 'text' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ—: '{text_column}'")
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df)}ä»¶")
    
    # é–¾å€¤è¨­å®šã®è¡¨ç¤º
    if threshold_config and threshold_config.get('use_threshold'):
        print(f"âš™ï¸  é–¾å€¤è¨­å®š:")
        print(f"  - ãƒã‚¬ãƒ†ã‚£ãƒ–é–¾å€¤: {threshold_config['negative_threshold']}")
        print(f"  - ãƒã‚¸ãƒ†ã‚£ãƒ–é–¾å€¤: {threshold_config['positive_threshold']}")
    else:
        print(f"âš™ï¸  åˆ¤å®šæ–¹å¼: æœ€å¤§ç¢ºç‡æ–¹å¼")
    
    # å‰å‡¦ç†
    texts = df[text_column].apply(preprocess_text).tolist()
    
    # BERTæ¨è«–
    results = analyze_with_bert(texts, tokenizer, model, device, 
                               threshold_config=threshold_config)
    
    # çµæœã‚’DataFrameã«è¿½åŠ 
    df["bert_label"] = [r["label"] for r in results]
    df["bert_positive"] = [r["positive"] for r in results]
    df["bert_neutral"] = [r["neutral"] for r in results]
    df["bert_negative"] = [r["negative"] for r in results]
    
    # çµ±è¨ˆæƒ…å ±
    label_counts = df["bert_label"].value_counts()
    print(f"\nâœ“ æ„Ÿæƒ…åˆ†æå®Œäº†:")
    for label, count in label_counts.items():
        percentage = (count / len(df)) * 100
        print(f"  - {label}: {count}ä»¶ ({percentage:.1f}%)")
    
    return df


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    if len(sys.argv) != 3:
        print("ä½¿ç”¨æ³•: python bert_sentiment.py <input_csv> <output_csv>")
        print("ä¾‹: python bert_sentiment.py original_data/tweets_xxx.csv output/bert_xxx.csv")
        sys.exit(1)
    
    input_path = sys.argv[1]
    output_path = sys.argv[2]
    
    print("=" * 60)
    print("æ—¥æœ¬èªBERTæ„Ÿæƒ…åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    
    # === é–¾å€¤è¨­å®šï¼ˆã“ã“ã§å¤‰æ›´å¯èƒ½ï¼‰===================================
    # use_threshold: False â†’ æœ€å¤§ç¢ºç‡æ–¹å¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    # use_threshold: True  â†’ é–¾å€¤ãƒ™ãƒ¼ã‚¹æ–¹å¼
    threshold_config = {
        'negative_threshold': 0.4,  # ãƒã‚¬ãƒ†ã‚£ãƒ–ã¨åˆ¤å®šã™ã‚‹æœ€ä½ç¢ºç‡ï¼ˆ0.0-1.0ï¼‰
        'positive_threshold': 0.4,  # ãƒã‚¸ãƒ†ã‚£ãƒ–ã¨åˆ¤å®šã™ã‚‹æœ€ä½ç¢ºç‡ï¼ˆ0.0-1.0ï¼‰
        'use_threshold': False      # True=é–¾å€¤ä½¿ç”¨, False=æœ€å¤§ç¢ºç‡
    }
    # ============================================================
    
    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    if not Path(input_path).exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
        sys.exit(1)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_dir = Path(output_path).parent
    if output_dir != Path('.'):
        output_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        # 1. ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        tokenizer, model, device = load_model()
        
        # 2. CSVèª­ã¿è¾¼ã¿
        print(f"\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {input_path}")
        df = pd.read_csv(input_path, comment='#')
        print(f"âœ“ {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        
        # 3. æ„Ÿæƒ…åˆ†æå®Ÿè¡Œ
        df_analyzed = process_dataframe(df, tokenizer, model, device, 
                                        threshold_config=threshold_config)
        
        # 4. çµæœä¿å­˜
        print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ä¸­: {output_path}")
        df_analyzed.to_csv(output_path, index=False)
        print(f"âœ“ ä¿å­˜å®Œäº†")
        
        print("\n" + "=" * 60)
        print("âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print("=" * 60)
        
    except ValueError as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()


# å®Ÿè¡Œä¾‹
# python bert_sentiment.py original_data/tweets_æ¾æœ¬äººå¿—_20251112_093317.csv sentiment_analysis/æ¾æœ¬äººå¿—_bert.csv
# python bert_sentiment.py original_data/tweets_xxx.csv output/bert_xxx.csv
