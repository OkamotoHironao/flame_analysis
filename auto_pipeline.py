#!/usr/bin/env python3
"""
å…¨è‡ªå‹•ç‚ä¸Šæ¤œçŸ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ v2

ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¾ã§ä¸€æ°—é€šè²«ã§å‡¦ç†

v2 æ”¹å–„ç‚¹:
- unified_model_v2ï¼ˆè¤‡åˆç‰¹å¾´é‡ï¼‰çµ±åˆ
- å…¨ãƒˆãƒ”ãƒƒã‚¯çµ±åˆå­¦ç¿’ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ 

ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:
- çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (data/standardized/{topic}.csv) ã‚’å„ªå…ˆä½¿ç”¨
- å­˜åœ¨ã—ãªã„å ´åˆã¯å¾“æ¥ã®çµåˆå‡¦ç†ã‚’å®Ÿè¡Œ
"""

import argparse
import subprocess
import sys
from pathlib import Path
import glob
import pandas as pd
import numpy as np


def run_command(cmd, description, background=False):
    """ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ"""
    print(f"\n{'='*60}")
    print(f"ğŸ”„ {description}")
    print(f"{'='*60}")
    
    # ä»®æƒ³ç’°å¢ƒã‚’ä½¿ã†
    venv_python = "python3"  # æ—¢ã«ä»®æƒ³ç’°å¢ƒå†…ã§å®Ÿè¡Œã•ã‚Œã‚‹å‰æ
    
    print(f"$ {cmd}")
    
    result = subprocess.run(
        cmd,
        shell=True,
        capture_output=not background,
        text=True,
        executable='/bin/bash'
    )
    
    if result.returncode != 0 and not background:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {description}ãŒå¤±æ•—ã—ã¾ã—ãŸ")
        if result.stderr:
            print(result.stderr)
        return False
    
    if not background and result.stdout:
        print(result.stdout)
    
    return True


def combine_csv_files(topic_name, data_dir):
    """è¤‡æ•°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’1ã¤ã«çµåˆ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“‚ CSVãƒ•ã‚¡ã‚¤ãƒ«çµåˆ: {topic_name}")
    print(f"{'='*60}")
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
    pattern = f"{data_dir}/**/*.csv"
    files = sorted(glob.glob(pattern, recursive=True))
    
    if not files:
        print(f"âš ï¸  CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
        return None
    
    print(f"âœ“ {len(files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹")
    
    # çµåˆ
    dfs = []
    for f in files:
        try:
            df = pd.read_csv(f, comment='#')
            dfs.append(df)
            print(f"  âœ“ {Path(f).name}: {len(df)}ä»¶")
        except Exception as e:
            print(f"  âš ï¸  ã‚¹ã‚­ãƒƒãƒ—: {Path(f).name} ({e})")
            continue
    
    if not dfs:
        print("âŒ èª­ã¿è¾¼ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    # çµåˆ
    combined = pd.concat(dfs, ignore_index=True)
    print(f"\nâœ“ çµåˆå®Œäº†: {len(combined)}ä»¶")
    
    # é‡è¤‡å‰Šé™¤ï¼ˆcontentåˆ—ãŒã‚ã‚‹å ´åˆï¼‰
    if 'content' in combined.columns:
        before = len(combined)
        combined = combined.drop_duplicates(subset=['content'], keep='first')
        print(f"âœ“ é‡è¤‡å‰Šé™¤: {before}ä»¶ â†’ {len(combined)}ä»¶")
    
    # ä¿å­˜
    output_path = f"data/original/{topic_name}_combined.csv"
    combined.to_csv(output_path, index=False)
    print(f"âœ“ ä¿å­˜: {output_path}")
    
    return output_path


def combine_sentiment_results(topic_name):
    """æ„Ÿæƒ…åˆ†æçµæœï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’1ã¤ã«çµåˆ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æ„Ÿæƒ…åˆ†æçµæœã‚’çµåˆ: {topic_name}")
    print(f"{'='*60}")
    
    # æ„Ÿæƒ…åˆ†æçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    pattern = f"data/processed/{topic_name}*_sentiment_1h.csv"
    files = sorted(glob.glob(pattern))
    
    if not files:
        print(f"âš ï¸  æ„Ÿæƒ…åˆ†æçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
        return None
    
    print(f"âœ“ {len(files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹")
    
    # çµåˆ
    dfs = []
    for f in files:
        try:
            df = pd.read_csv(f)
            dfs.append(df)
        except:
            continue
    
    if not dfs:
        return None
    
    combined = pd.concat(dfs, ignore_index=True)
    
    # timestampã§ã‚½ãƒ¼ãƒˆã—ã¦é‡è¤‡å‰Šé™¤
    combined['timestamp'] = pd.to_datetime(combined['timestamp'])
    combined = combined.sort_values('timestamp')
    combined = combined.drop_duplicates(subset=['timestamp'], keep='first')
    
    print(f"âœ“ çµåˆå®Œäº†: {len(combined)}æ™‚é–“åˆ†")
    
    # ä¿å­˜
    output_path = f"data/processed/{topic_name}_sentiment_1h.csv"
    combined.to_csv(output_path, index=False)
    print(f"âœ“ ä¿å­˜: {output_path}")
    
    return output_path


def run_unified_training(topics_str=None):
    """
    å…¨ãƒˆãƒ”ãƒƒã‚¯çµ±åˆå­¦ç¿’ï¼ˆtrain_unified_model_v2.pyï¼‰ã‚’å®Ÿè¡Œ
    """
    print("="*60)
    print("ğŸ”¥ å…¨ãƒˆãƒ”ãƒƒã‚¯çµ±åˆå­¦ç¿’")
    print("="*60)
    
    cmd = "cd modules/flame_detection && python3 train_unified_model_v2.py"
    
    if topics_str:
        cmd += f" --topics {topics_str}"
    
    if not run_command(cmd, "çµ±åˆå­¦ç¿’ (v2)"):
        sys.exit(1)
    
    print("\nâœ… çµ±åˆå­¦ç¿’å®Œäº†ï¼")
    print("ğŸ“‚ å‡ºåŠ›: modules/flame_detection/outputs/unified_model_v2/")


def main():
    parser = argparse.ArgumentParser(
        description='å…¨è‡ªå‹•ç‚ä¸Šæ¤œçŸ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ v2',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ä¸‰è‹«ã®å…¨å‡¦ç†
  python3 auto_pipeline.py ä¸‰è‹«
  
  # aespaã®å…¨å‡¦ç†
  python3 auto_pipeline.py aespa
  
  # ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã ã‘å®Ÿè¡Œ
  python3 auto_pipeline.py ä¸‰è‹« --steps sentiment,stance
  
  # å­¦ç¿’ã‚’ã‚¹ã‚­ãƒƒãƒ—
  python3 auto_pipeline.py ä¸‰è‹« --skip-training
  
  # å…¨ãƒˆãƒ”ãƒƒã‚¯çµ±åˆå­¦ç¿’
  python3 auto_pipeline.py --unified-train
        """
    )
    
    parser.add_argument(
        'topic',
        type=str,
        nargs='?',
        default=None,
        help='ãƒˆãƒ”ãƒƒã‚¯åï¼ˆä¾‹: ä¸‰è‹«, aespa, æ¾æœ¬äººå¿—ï¼‰'
    )
    
    parser.add_argument(
        '--steps',
        type=str,
        default='all',
        help='å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š: combine,sentiment,stance,feature,visualize,label,trainï¼‰'
    )
    
    parser.add_argument(
        '--skip-training',
        action='store_true',
        help='ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’ã‚¹ã‚­ãƒƒãƒ—'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ã'
    )
    
    parser.add_argument(
        '--unified-train',
        action='store_true',
        help='å…¨ãƒˆãƒ”ãƒƒã‚¯ã§çµ±åˆå­¦ç¿’ï¼ˆtrain_unified_model_v2.pyï¼‰'
    )
    
    parser.add_argument(
        '--unified-topics',
        type=str,
        default=None,
        help='çµ±åˆå­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹ãƒˆãƒ”ãƒƒã‚¯ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰'
    )
    
    args = parser.parse_args()
    
    # çµ±åˆå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰
    if args.unified_train:
        run_unified_training(args.unified_topics)
        return
    
    # ãƒˆãƒ”ãƒƒã‚¯å¿…é ˆãƒã‚§ãƒƒã‚¯
    if args.topic is None:
        parser.error("ãƒˆãƒ”ãƒƒã‚¯åã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆã¾ãŸã¯ --unified-train ã‚’ä½¿ç”¨ï¼‰")
    
    topic = args.topic
    
    # ã‚¹ãƒ†ãƒƒãƒ—è¨­å®š
    if args.steps == 'all':
        steps = ['combine', 'sentiment', 'stance', 'feature', 'visualize', 'label', 'train']
    else:
        steps = [s.strip() for s in args.steps.split(',')]
    
    if args.skip_training and 'train' in steps:
        steps.remove('train')
    
    print("="*60)
    print(f"ğŸ”¥ å…¨è‡ªå‹•ç‚ä¸Šæ¤œçŸ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    print("="*60)
    print(f"  ãƒˆãƒ”ãƒƒã‚¯: {topic}")
    print(f"  å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—: {', '.join(steps)}")
    print("="*60)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    Path("data/processed").mkdir(parents=True, exist_ok=True)
    Path(f"modules/stance_detection/outputs/{topic}").mkdir(parents=True, exist_ok=True)
    Path(f"modules/feature_engineering/outputs/{topic}").mkdir(parents=True, exist_ok=True)
    Path(f"modules/flame_detection/outputs/{topic}").mkdir(parents=True, exist_ok=True)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
    data_dir = f"data/original/{topic}"
    standardized_csv = f"data/standardized/{topic}.csv"
    
    # çµ±ä¸€CSVãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    use_standardized = Path(standardized_csv).exists()
    
    if use_standardized:
        print(f"âœ“ çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆCSVã‚’ä½¿ç”¨: {standardized_csv}")
        combined_csv = standardized_csv
    elif not Path(data_dir).exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print(f"   çµ±ä¸€CSV: {standardized_csv}")
        print(f"   ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {data_dir}")
        print(f"\n   ã¾ãš standardize_csv.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print(f"   â†’ python3 standardize_csv.py {topic}")
        sys.exit(1)
    else:
        combined_csv = f"data/original/{topic}_combined.csv"
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    bert_output_csv = f"data/processed/{topic}_bert.csv"
    sentiment_csv = f"data/processed/{topic}_sentiment_1h.csv"
    stance_csv = f"modules/stance_detection/outputs/{topic}/{topic}_stance.csv"
    feature_csv = f"modules/feature_engineering/outputs/{topic}/{topic}_feature_table.csv"
    labeled_csv = f"modules/flame_detection/outputs/{topic}/{topic}_labeled.csv"
    
    # ========================================
    # Step 1: CSVãƒ•ã‚¡ã‚¤ãƒ«çµåˆï¼ˆçµ±ä¸€CSVä½¿ç”¨æ™‚ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    # ========================================
    if 'combine' in steps:
        if use_standardized:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆCSVã‚’ä½¿ç”¨ä¸­")
        elif args.force or not Path(combined_csv).exists():
            combined_csv = combine_csv_files(topic, data_dir)
            if not combined_csv:
                print("âŒ CSVçµåˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                sys.exit(1)
        else:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {combined_csv} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 2: æ„Ÿæƒ…åˆ†æï¼ˆBERTãƒ™ãƒ¼ã‚¹ï¼‰
    # ========================================
    if 'sentiment' in steps:
        if args.force or not Path(sentiment_csv).exists():
            # Step 2-1: BERTæ„Ÿæƒ…åˆ†æ
            if not run_command(
                f"python3 bert_sentiment.py {combined_csv} {bert_output_csv}",
                "æ„Ÿæƒ…åˆ†æï¼ˆBERTï¼‰"
            ):
                sys.exit(1)
            
            # Step 2-2: æ™‚ç³»åˆ—é›†è¨ˆ
            if not run_command(
                f"python3 bert_sentiment_timeseries.py {bert_output_csv} {sentiment_csv}",
                "æ™‚ç³»åˆ—é›†è¨ˆ"
            ):
                sys.exit(1)
        else:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {sentiment_csv} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 3: ç«‹å ´æ¤œå‡º
    # ========================================
    if 'stance' in steps:
        if args.force or not Path(stance_csv).exists():
            if not run_command(
                f"python3 stance_predict.py {combined_csv} {stance_csv}",
                "ç«‹å ´æ¤œå‡º"
            ):
                sys.exit(1)
        else:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {stance_csv} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 4: ç‰¹å¾´é‡çµ±åˆ
    # ========================================
    if 'feature' in steps:
        if args.force or not Path(feature_csv).exists():
            if not run_command(
                f"cd modules/feature_engineering && python3 feature_builder.py "
                f"--sentiment_csv ../../{sentiment_csv} "
                f"--stance_csv ../../{stance_csv}",
                "ç‰¹å¾´é‡çµ±åˆ"
            ):
                sys.exit(1)
        else:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {feature_csv} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 5: å¯è¦–åŒ–
    # ========================================
    if 'visualize' in steps:
        vis_output = f"modules/flame_detection/outputs/{topic}_feature_trends.png"
        if args.force or not Path(vis_output).exists():
            if not run_command(
                f"python3 visualize_features.py {feature_csv} {vis_output}",
                "ç‰¹å¾´é‡å¯è¦–åŒ–"
            ):
                sys.exit(1)
        else:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {vis_output} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 6: ãƒ©ãƒ™ãƒªãƒ³ã‚°
    # ========================================
    if 'label' in steps:
        label_config = f"modules/flame_detection/label_config_{topic}.yaml"
        
        if not Path(label_config).exists():
            print(f"\nâš ï¸  è­¦å‘Š: ãƒ©ãƒ™ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {label_config}")
            print(f"   å¯è¦–åŒ–çµæœã‚’ç¢ºèªã—ã¦ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„:")
            print(f"   â†’ code {label_config}")
            print(f"\n   ãã®å¾Œã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ:")
            print(f"   â†’ python3 modules/flame_detection/label_windows.py \\")
            print(f"       {feature_csv} \\")
            print(f"       {label_config} \\")
            print(f"       {labeled_csv}")
        else:
            if args.force or not Path(labeled_csv).exists():
                if not run_command(
                    f"cd modules/flame_detection && python3 label_windows.py "
                    f"../../{feature_csv} "
                    f"label_config_{topic}.yaml "
                    f"outputs/{topic}/{topic}_labeled.csv",
                    "ãƒ©ãƒ™ãƒªãƒ³ã‚°"
                ):
                    sys.exit(1)
            else:
                print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {labeled_csv} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 7: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆãƒˆãƒ”ãƒƒã‚¯å˜ä½“ï¼‰
    # ========================================
    if 'train' in steps:
        model_output = f"modules/flame_detection/outputs/{topic}/model/model.pkl"
        
        if not Path(labeled_csv).exists():
            print(f"\nâš ï¸  è­¦å‘Š: ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {labeled_csv}")
            print(f"   å…ˆã«ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        else:
            if args.force or not Path(model_output).exists():
                if not run_command(
                    f"cd modules/flame_detection && python3 train_classifier.py "
                    f"outputs/{topic}/{topic}_labeled.csv "
                    f"outputs/{topic}/model/",
                    "ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆãƒˆãƒ”ãƒƒã‚¯å˜ä½“ï¼‰"
                ):
                    sys.exit(1)
            else:
                print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {model_output} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # å®Œäº†
    # ========================================
    print("\n" + "="*60)
    print("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ï¼")
    print("="*60)
    
    print(f"\nğŸ“‚ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
    if Path(combined_csv).exists():
        print(f"  âœ“ çµåˆãƒ‡ãƒ¼ã‚¿: {combined_csv}")
    if Path(bert_output_csv).exists():
        print(f"  âœ“ BERTæ„Ÿæƒ…åˆ†æ: {bert_output_csv}")
    if Path(sentiment_csv).exists():
        print(f"  âœ“ æ™‚ç³»åˆ—é›†è¨ˆ: {sentiment_csv}")
    if Path(stance_csv).exists():
        print(f"  âœ“ ç«‹å ´æ¤œå‡º: {stance_csv}")
    if Path(feature_csv).exists():
        print(f"  âœ“ ç‰¹å¾´é‡: {feature_csv}")
    if Path(labeled_csv).exists():
        print(f"  âœ“ ãƒ©ãƒ™ãƒ«ä»˜ã: {labeled_csv}")
    if Path(f"modules/flame_detection/outputs/{topic}/model/model.pkl").exists():
        print(f"  âœ“ ãƒ¢ãƒ‡ãƒ«: modules/flame_detection/outputs/{topic}/model/")
    
    print(f"\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"  # å…¨ãƒˆãƒ”ãƒƒã‚¯çµ±åˆå­¦ç¿’ï¼ˆæ¨å¥¨ï¼‰:")
    print(f"  python3 auto_pipeline.py --unified-train")
    print(f"\n  # ç‰¹å®šãƒˆãƒ”ãƒƒã‚¯ã§çµ±åˆå­¦ç¿’:")
    print(f"  python3 auto_pipeline.py --unified-train --unified-topics æ¾æœ¬äººå¿—,ä¸‰è‹«,å¯¿å¸ãƒšãƒ­")
    print()


if __name__ == '__main__':
    main()
