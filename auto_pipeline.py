#!/usr/bin/env python3
"""
å…¨è‡ªå‹•ç‚ä¸Šæ¤œçŸ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ v2

ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¾ã§ä¸€æ°—é€šè²«ã§å‡¦ç†

v2 æ”¹å–„ç‚¹:
- enhanced_sentimentï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ–ãƒ¼ã‚¹ãƒˆï¼‰çµ±åˆ
- unified_model_v2ï¼ˆè¤‡åˆç‰¹å¾´é‡ï¼‰çµ±åˆ
- å…¨ãƒˆãƒ”ãƒƒã‚¯çµ±åˆå­¦ç¿’ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ 

ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:
- çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (data/standardized/{topic}.csv) ã‚’å„ªå…ˆä½¿ç”¨
- å­˜åœ¨ã—ãªã„å ´åˆã¯å¾“æ¥ã®çµåˆå‡¦ç†ã‚’å®Ÿè¡Œ
"""

import argparse
import subprocess
import sys
from pathlib import Path
import glob
import pandas as pd
import numpy as np


def run_command(cmd, description, background=False):
    """ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ"""
    print(f"\n{'='*60}")
    print(f"ğŸ”„ {description}")
    print(f"{'='*60}")
    
    # ä»®æƒ³ç’°å¢ƒã‚’ä½¿ã†
    venv_python = "python3"  # æ—¢ã«ä»®æƒ³ç’°å¢ƒå†…ã§å®Ÿè¡Œã•ã‚Œã‚‹å‰æ
    
    print(f"$ {cmd}")
    
    result = subprocess.run(
        cmd,
        shell=True,
        capture_output=not background,
        text=True,
        executable='/bin/bash'
    )
    
    if result.returncode != 0 and not background:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {description}ãŒå¤±æ•—ã—ã¾ã—ãŸ")
        if result.stderr:
            print(result.stderr)
        return False
    
    if not background and result.stdout:
        print(result.stdout)
    
    return True


def combine_csv_files(topic_name, data_dir):
    """è¤‡æ•°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’1ã¤ã«çµåˆ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“‚ CSVãƒ•ã‚¡ã‚¤ãƒ«çµåˆ: {topic_name}")
    print(f"{'='*60}")
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
    pattern = f"{data_dir}/**/*.csv"
    files = sorted(glob.glob(pattern, recursive=True))
    
    if not files:
        print(f"âš ï¸  CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
        return None
    
    print(f"âœ“ {len(files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹")
    
    # çµåˆ
    dfs = []
    for f in files:
        try:
            df = pd.read_csv(f, comment='#')
            dfs.append(df)
            print(f"  âœ“ {Path(f).name}: {len(df)}ä»¶")
        except Exception as e:
            print(f"  âš ï¸  ã‚¹ã‚­ãƒƒãƒ—: {Path(f).name} ({e})")
            continue
    
    if not dfs:
        print("âŒ èª­ã¿è¾¼ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    # çµåˆ
    combined = pd.concat(dfs, ignore_index=True)
    print(f"\nâœ“ çµåˆå®Œäº†: {len(combined)}ä»¶")
    
    # é‡è¤‡å‰Šé™¤ï¼ˆcontentåˆ—ãŒã‚ã‚‹å ´åˆï¼‰
    if 'content' in combined.columns:
        before = len(combined)
        combined = combined.drop_duplicates(subset=['content'], keep='first')
        print(f"âœ“ é‡è¤‡å‰Šé™¤: {before}ä»¶ â†’ {len(combined)}ä»¶")
    
    # ä¿å­˜
    output_path = f"data/original/{topic_name}_combined.csv"
    combined.to_csv(output_path, index=False)
    print(f"âœ“ ä¿å­˜: {output_path}")
    
    return output_path


def combine_sentiment_results(topic_name):
    """æ„Ÿæƒ…åˆ†æçµæœï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’1ã¤ã«çµåˆ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æ„Ÿæƒ…åˆ†æçµæœã‚’çµåˆ: {topic_name}")
    print(f"{'='*60}")
    
    # æ„Ÿæƒ…åˆ†æçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    pattern = f"data/processed/{topic_name}*_sentiment_1h.csv"
    files = sorted(glob.glob(pattern))
    
    if not files:
        print(f"âš ï¸  æ„Ÿæƒ…åˆ†æçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
        return None
    
    print(f"âœ“ {len(files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹")
    
    # çµåˆ
    dfs = []
    for f in files:
        try:
            df = pd.read_csv(f)
            dfs.append(df)
        except:
            continue
    
    if not dfs:
        return None
    
    combined = pd.concat(dfs, ignore_index=True)
    
    # timestampã§ã‚½ãƒ¼ãƒˆã—ã¦é‡è¤‡å‰Šé™¤
    combined['timestamp'] = pd.to_datetime(combined['timestamp'])
    combined = combined.sort_values('timestamp')
    combined = combined.drop_duplicates(subset=['timestamp'], keep='first')
    
    print(f"âœ“ çµåˆå®Œäº†: {len(combined)}æ™‚é–“åˆ†")
    
    # ä¿å­˜
    output_path = f"data/processed/{topic_name}_sentiment_1h.csv"
    combined.to_csv(output_path, index=False)
    print(f"âœ“ ä¿å­˜: {output_path}")
    
    return output_path


def apply_enhanced_sentiment(bert_csv, stance_csv, output_csv):
    """
    enhanced_sentimentã‚’é©ç”¨ã—ã¦æ„Ÿæƒ…åˆ†æã‚’è£œæ­£
    
    BERTã®æ„Ÿæƒ…åˆ†æçµæœã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ–ãƒ¼ã‚¹ãƒˆï¼‹ã‚¹ã‚¿ãƒ³ã‚¹çµ±åˆã‚’é©ç”¨
    """
    print(f"\n{'='*60}")
    print(f"ğŸ”§ æ„Ÿæƒ…åˆ†æè£œæ­£ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ–ãƒ¼ã‚¹ãƒˆï¼‹ã‚¹ã‚¿ãƒ³ã‚¹çµ±åˆï¼‰")
    print(f"{'='*60}")
    
    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    sys.path.insert(0, str(Path(__file__).parent / "modules" / "sentiment_analysis"))
    from enhanced_sentiment import calculate_enhanced_negativity, compare_methods
    
    # BERTãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_csv(bert_csv)
    print(f"âœ“ BERTçµæœèª­ã¿è¾¼ã¿: {len(df)}ä»¶")
    
    # ã‚«ãƒ©ãƒ åã®æ­£è¦åŒ–
    col_mapping = {
        'negative': 'bert_negative',
        'positive': 'bert_positive',
        'neutral': 'bert_neutral',
        'label': 'bert_label',
    }
    for old, new in col_mapping.items():
        if old in df.columns and new not in df.columns:
            df[new] = df[old]
    
    # ã‚¹ã‚¿ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°çµåˆ
    if Path(stance_csv).exists():
        stance_df = pd.read_csv(stance_csv)
        print(f"âœ“ ã‚¹ã‚¿ãƒ³ã‚¹çµæœèª­ã¿è¾¼ã¿: {len(stance_df)}ä»¶")
        
        # ã‚¹ã‚¿ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆï¼ˆcontentåˆ—ã§ï¼‰
        if 'content' in df.columns and 'content' in stance_df.columns:
            stance_subset = stance_df[['content', 'stance_label']].drop_duplicates(subset=['content'])
            df = df.merge(stance_subset, on='content', how='left')
            df['stance_label'] = df['stance_label'].fillna('NEUTRAL')
    else:
        print(f"âš ï¸ ã‚¹ã‚¿ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãªã—: ã‚¹ã‚¿ãƒ³ã‚¹çµ±åˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
        df['stance_label'] = 'NEUTRAL'
    
    # enhanced_sentimenté©ç”¨
    df = calculate_enhanced_negativity(
        df,
        bert_weight=0.4,
        keyword_weight=0.3,
        stance_weight=0.3,
        content_col='content',
        bert_neg_col='bert_negative',
        bert_label_col='bert_label',
        stance_col='stance_label',
    )
    
    # æ¯”è¼ƒçµ±è¨ˆ
    if 'bert_label' in df.columns:
        stats = compare_methods(df)
        print(f"\nğŸ“Š è£œæ­£åŠ¹æœ:")
        print(f"  BERT NEGATIVE:     {stats['bert_negative']}ä»¶ ({stats['bert_negative']/stats['total']*100:.1f}%)")
        print(f"  è£œæ­£å¾Œ NEGATIVE:   {stats['enhanced_negative']}ä»¶ ({stats['enhanced_negative']/stats['total']*100:.1f}%)")
        print(f"  NEUTRALâ†’NEGATIVE:  {stats['neutral_to_negative']}ä»¶")
    
    # ä¿å­˜
    df.to_csv(output_csv, index=False)
    print(f"\nâœ“ è£œæ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {output_csv}")
    
    return df


def aggregate_enhanced_to_timeseries(enhanced_csv, output_csv):
    """
    enhanced_sentimentã®çµæœã‚’1æ™‚é–“ã”ã¨ã«é›†è¨ˆ
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“ˆ è£œæ­£æ¸ˆã¿æ„Ÿæƒ…åˆ†æã®æ™‚ç³»åˆ—é›†è¨ˆ")
    print(f"{'='*60}")
    
    df = pd.read_csv(enhanced_csv)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df['hour'] = df['timestamp'].dt.floor('h')
    
    # é›†è¨ˆ
    hourly = df.groupby('hour').agg({
        'content': 'count',
        'bert_negative': 'mean',
        'enhanced_negativity': 'mean',
        'enhanced_label': lambda x: (x == 'NEGATIVE').mean(),
    }).reset_index()
    
    hourly.columns = [
        'timestamp', 'count',
        'bert_negative_rate', 'enhanced_negative_score', 'negative_rate'
    ]
    
    # æ—¢å­˜å½¢å¼ã¨ã®äº’æ›æ€§ã®ãŸã‚è¿½åŠ 
    hourly['positive_count'] = 0  # ç°¡ç•¥åŒ–
    hourly['neutral_count'] = 0
    hourly['negative_count'] = (hourly['count'] * hourly['negative_rate']).astype(int)
    
    print(f"âœ“ {len(hourly)}æ™‚é–“åˆ†ã®é›†è¨ˆå®Œäº†")
    print(f"  å¹³å‡ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡: {hourly['negative_rate'].mean()*100:.1f}%")
    
    hourly.to_csv(output_csv, index=False)
    print(f"âœ“ ä¿å­˜: {output_csv}")
    
    return hourly


def run_unified_training(topics_str=None):
    """
    å…¨ãƒˆãƒ”ãƒƒã‚¯çµ±åˆå­¦ç¿’ï¼ˆtrain_unified_model_v2.pyï¼‰ã‚’å®Ÿè¡Œ
    """
    print("="*60)
    print("ğŸ”¥ å…¨ãƒˆãƒ”ãƒƒã‚¯çµ±åˆå­¦ç¿’")
    print("="*60)
    
    cmd = "cd modules/flame_detection && python3 train_unified_model_v2.py"
    
    if topics_str:
        cmd += f" --topics {topics_str}"
    
    if not run_command(cmd, "çµ±åˆå­¦ç¿’ (v2)"):
        sys.exit(1)
    
    print("\nâœ… çµ±åˆå­¦ç¿’å®Œäº†ï¼")
    print("ğŸ“‚ å‡ºåŠ›: modules/flame_detection/outputs/unified_model_v2/")


def main():
    parser = argparse.ArgumentParser(
        description='å…¨è‡ªå‹•ç‚ä¸Šæ¤œçŸ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ v2',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ä¸‰è‹«ã®å…¨å‡¦ç†
  python3 auto_pipeline.py ä¸‰è‹«
  
  # aespaã®å…¨å‡¦ç†
  python3 auto_pipeline.py aespa
  
  # ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã ã‘å®Ÿè¡Œ
  python3 auto_pipeline.py ä¸‰è‹« --steps sentiment,stance
  
  # å­¦ç¿’ã‚’ã‚¹ã‚­ãƒƒãƒ—
  python3 auto_pipeline.py ä¸‰è‹« --skip-training
  
  # å…¨ãƒˆãƒ”ãƒƒã‚¯çµ±åˆå­¦ç¿’
  python3 auto_pipeline.py --unified-train
  
  # æ„Ÿæƒ…è£œæ­£ã‚ã‚Šï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ–ãƒ¼ã‚¹ãƒˆï¼‰
  python3 auto_pipeline.py ä¸‰è‹« --enhanced-sentiment
        """
    )
    
    parser.add_argument(
        'topic',
        type=str,
        nargs='?',
        default=None,
        help='ãƒˆãƒ”ãƒƒã‚¯åï¼ˆä¾‹: ä¸‰è‹«, aespa, æ¾æœ¬äººå¿—ï¼‰'
    )
    
    parser.add_argument(
        '--steps',
        type=str,
        default='all',
        help='å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š: combine,sentiment,enhance,stance,feature,visualize,label,trainï¼‰'
    )
    
    parser.add_argument(
        '--skip-training',
        action='store_true',
        help='ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’ã‚¹ã‚­ãƒƒãƒ—'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ã'
    )
    
    parser.add_argument(
        '--enhanced-sentiment',
        action='store_true',
        help='æ„Ÿæƒ…åˆ†æè£œæ­£ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ–ãƒ¼ã‚¹ãƒˆï¼‹ã‚¹ã‚¿ãƒ³ã‚¹çµ±åˆï¼‰ã‚’é©ç”¨'
    )
    
    parser.add_argument(
        '--unified-train',
        action='store_true',
        help='å…¨ãƒˆãƒ”ãƒƒã‚¯ã§çµ±åˆå­¦ç¿’ï¼ˆtrain_unified_model_v2.pyï¼‰'
    )
    
    parser.add_argument(
        '--unified-topics',
        type=str,
        default=None,
        help='çµ±åˆå­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹ãƒˆãƒ”ãƒƒã‚¯ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰'
    )
    
    args = parser.parse_args()
    
    # çµ±åˆå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰
    if args.unified_train:
        run_unified_training(args.unified_topics)
        return
    
    # ãƒˆãƒ”ãƒƒã‚¯å¿…é ˆãƒã‚§ãƒƒã‚¯
    if args.topic is None:
        parser.error("ãƒˆãƒ”ãƒƒã‚¯åã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆã¾ãŸã¯ --unified-train ã‚’ä½¿ç”¨ï¼‰")
    
    topic = args.topic
    
    # ã‚¹ãƒ†ãƒƒãƒ—è¨­å®š
    if args.steps == 'all':
        steps = ['combine', 'sentiment', 'stance', 'feature', 'visualize', 'label', 'train']
        # enhanced-sentimentã‚ªãƒ—ã‚·ãƒ§ãƒ³æ™‚ã¯'enhance'ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¿½åŠ 
        if args.enhanced_sentiment:
            steps.insert(steps.index('stance') + 1, 'enhance')
    else:
        steps = [s.strip() for s in args.steps.split(',')]
    
    if args.skip_training and 'train' in steps:
        steps.remove('train')
    
    print("="*60)
    print(f"ğŸ”¥ å…¨è‡ªå‹•ç‚ä¸Šæ¤œçŸ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    print("="*60)
    print(f"  ãƒˆãƒ”ãƒƒã‚¯: {topic}")
    print(f"  å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—: {', '.join(steps)}")
    print("="*60)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    Path("data/processed").mkdir(parents=True, exist_ok=True)
    Path(f"modules/stance_detection/outputs/{topic}").mkdir(parents=True, exist_ok=True)
    Path(f"modules/feature_engineering/outputs/{topic}").mkdir(parents=True, exist_ok=True)
    Path(f"modules/flame_detection/outputs/{topic}").mkdir(parents=True, exist_ok=True)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
    data_dir = f"data/original/{topic}"
    standardized_csv = f"data/standardized/{topic}.csv"
    
    # çµ±ä¸€CSVãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    use_standardized = Path(standardized_csv).exists()
    
    if use_standardized:
        print(f"âœ“ çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆCSVã‚’ä½¿ç”¨: {standardized_csv}")
        combined_csv = standardized_csv
    elif not Path(data_dir).exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print(f"   çµ±ä¸€CSV: {standardized_csv}")
        print(f"   ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {data_dir}")
        print(f"\n   ã¾ãš standardize_csv.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print(f"   â†’ python3 standardize_csv.py {topic}")
        sys.exit(1)
    else:
        combined_csv = f"data/original/{topic}_combined.csv"
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    bert_output_csv = f"data/processed/{topic}_bert.csv"
    sentiment_csv = f"data/processed/{topic}_sentiment_1h.csv"
    stance_csv = f"modules/stance_detection/outputs/{topic}/{topic}_stance.csv"
    feature_csv = f"modules/feature_engineering/outputs/{topic}/{topic}_feature_table.csv"
    labeled_csv = f"modules/flame_detection/outputs/{topic}/{topic}_labeled.csv"
    
    # ========================================
    # Step 1: CSVãƒ•ã‚¡ã‚¤ãƒ«çµåˆï¼ˆçµ±ä¸€CSVä½¿ç”¨æ™‚ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    # ========================================
    if 'combine' in steps:
        if use_standardized:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆCSVã‚’ä½¿ç”¨ä¸­")
        elif args.force or not Path(combined_csv).exists():
            combined_csv = combine_csv_files(topic, data_dir)
            if not combined_csv:
                print("âŒ CSVçµåˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                sys.exit(1)
        else:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {combined_csv} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 2: æ„Ÿæƒ…åˆ†æï¼ˆBERTãƒ™ãƒ¼ã‚¹ï¼‰
    # ========================================
    if 'sentiment' in steps:
        if args.force or not Path(sentiment_csv).exists():
            # Step 2-1: BERTæ„Ÿæƒ…åˆ†æ
            if not run_command(
                f"python3 bert_sentiment.py {combined_csv} {bert_output_csv}",
                "æ„Ÿæƒ…åˆ†æï¼ˆBERTï¼‰"
            ):
                sys.exit(1)
            
            # Step 2-2: æ™‚ç³»åˆ—é›†è¨ˆ
            if not run_command(
                f"python3 bert_sentiment_timeseries.py {bert_output_csv} {sentiment_csv}",
                "æ™‚ç³»åˆ—é›†è¨ˆ"
            ):
                sys.exit(1)
        else:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {sentiment_csv} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 3: ç«‹å ´æ¤œå‡º
    # ========================================
    if 'stance' in steps:
        if args.force or not Path(stance_csv).exists():
            if not run_command(
                f"python3 stance_predict.py {combined_csv} {stance_csv}",
                "ç«‹å ´æ¤œå‡º"
            ):
                sys.exit(1)
        else:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {stance_csv} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 3.5: æ„Ÿæƒ…åˆ†æè£œæ­£ï¼ˆenhanced_sentimentï¼‰
    # ========================================
    enhanced_csv = f"data/processed/{topic}_enhanced.csv"
    enhanced_sentiment_csv = f"data/processed/{topic}_enhanced_sentiment_1h.csv"
    
    if 'enhance' in steps:
        if args.force or not Path(enhanced_csv).exists():
            # è£œæ­£ã‚’é©ç”¨
            apply_enhanced_sentiment(bert_output_csv, stance_csv, enhanced_csv)
            
            # è£œæ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—é›†è¨ˆ
            aggregate_enhanced_to_timeseries(enhanced_csv, enhanced_sentiment_csv)
            
            # è£œæ­£æ¸ˆã¿ã®æ„Ÿæƒ…CSVã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†åˆ‡ã‚Šæ›¿ãˆ
            sentiment_csv = enhanced_sentiment_csv
            print(f"\nâœ“ æ„Ÿæƒ…åˆ†æã‚’è£œæ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã«åˆ‡ã‚Šæ›¿ãˆ: {sentiment_csv}")
        else:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {enhanced_csv} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
            # è£œæ­£æ¸ˆã¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
            sentiment_csv = enhanced_sentiment_csv
    
    # ========================================
    # Step 4: ç‰¹å¾´é‡çµ±åˆ
    # ========================================
    if 'feature' in steps:
        if args.force or not Path(feature_csv).exists():
            if not run_command(
                f"cd modules/feature_engineering && python3 feature_builder.py "
                f"--sentiment_csv ../../{sentiment_csv} "
                f"--stance_csv ../../{stance_csv}",
                "ç‰¹å¾´é‡çµ±åˆ"
            ):
                sys.exit(1)
        else:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {feature_csv} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 5: å¯è¦–åŒ–
    # ========================================
    if 'visualize' in steps:
        vis_output = f"modules/flame_detection/outputs/{topic}_feature_trends.png"
        if args.force or not Path(vis_output).exists():
            if not run_command(
                f"python3 visualize_features.py {feature_csv} {vis_output}",
                "ç‰¹å¾´é‡å¯è¦–åŒ–"
            ):
                sys.exit(1)
        else:
            print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {vis_output} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 6: ãƒ©ãƒ™ãƒªãƒ³ã‚°
    # ========================================
    if 'label' in steps:
        label_config = f"modules/flame_detection/label_config_{topic}.yaml"
        
        if not Path(label_config).exists():
            print(f"\nâš ï¸  è­¦å‘Š: ãƒ©ãƒ™ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {label_config}")
            print(f"   å¯è¦–åŒ–çµæœã‚’ç¢ºèªã—ã¦ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„:")
            print(f"   â†’ code {label_config}")
            print(f"\n   ãã®å¾Œã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ:")
            print(f"   â†’ python3 modules/flame_detection/label_windows.py \\")
            print(f"       {feature_csv} \\")
            print(f"       {label_config} \\")
            print(f"       {labeled_csv}")
        else:
            if args.force or not Path(labeled_csv).exists():
                if not run_command(
                    f"cd modules/flame_detection && python3 label_windows.py "
                    f"../../{feature_csv} "
                    f"label_config_{topic}.yaml "
                    f"outputs/{topic}/{topic}_labeled.csv",
                    "ãƒ©ãƒ™ãƒªãƒ³ã‚°"
                ):
                    sys.exit(1)
            else:
                print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {labeled_csv} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # Step 7: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆãƒˆãƒ”ãƒƒã‚¯å˜ä½“ï¼‰
    # ========================================
    if 'train' in steps:
        model_output = f"modules/flame_detection/outputs/{topic}/model/model.pkl"
        
        if not Path(labeled_csv).exists():
            print(f"\nâš ï¸  è­¦å‘Š: ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {labeled_csv}")
            print(f"   å…ˆã«ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        else:
            if args.force or not Path(model_output).exists():
                if not run_command(
                    f"cd modules/flame_detection && python3 train_classifier.py "
                    f"outputs/{topic}/{topic}_labeled.csv "
                    f"outputs/{topic}/model/",
                    "ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆãƒˆãƒ”ãƒƒã‚¯å˜ä½“ï¼‰"
                ):
                    sys.exit(1)
            else:
                print(f"\nâœ“ ã‚¹ã‚­ãƒƒãƒ—: {model_output} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # ========================================
    # å®Œäº†
    # ========================================
    print("\n" + "="*60)
    print("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ï¼")
    print("="*60)
    
    print(f"\nğŸ“‚ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
    if Path(combined_csv).exists():
        print(f"  âœ“ çµåˆãƒ‡ãƒ¼ã‚¿: {combined_csv}")
    if Path(bert_output_csv).exists():
        print(f"  âœ“ BERTæ„Ÿæƒ…åˆ†æ: {bert_output_csv}")
    if 'enhance' in steps and Path(enhanced_csv).exists():
        print(f"  âœ“ æ„Ÿæƒ…è£œæ­£: {enhanced_csv}")
    if Path(sentiment_csv).exists():
        print(f"  âœ“ æ™‚ç³»åˆ—é›†è¨ˆ: {sentiment_csv}")
    if Path(stance_csv).exists():
        print(f"  âœ“ ç«‹å ´æ¤œå‡º: {stance_csv}")
    if Path(feature_csv).exists():
        print(f"  âœ“ ç‰¹å¾´é‡: {feature_csv}")
    if Path(labeled_csv).exists():
        print(f"  âœ“ ãƒ©ãƒ™ãƒ«ä»˜ã: {labeled_csv}")
    if Path(f"modules/flame_detection/outputs/{topic}/model/model.pkl").exists():
        print(f"  âœ“ ãƒ¢ãƒ‡ãƒ«: modules/flame_detection/outputs/{topic}/model/")
    
    print(f"\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"  # å…¨ãƒˆãƒ”ãƒƒã‚¯çµ±åˆå­¦ç¿’ï¼ˆæ¨å¥¨ï¼‰:")
    print(f"  python3 auto_pipeline.py --unified-train")
    print(f"\n  # ç‰¹å®šãƒˆãƒ”ãƒƒã‚¯ã§çµ±åˆå­¦ç¿’:")
    print(f"  python3 auto_pipeline.py --unified-train --unified-topics æ¾æœ¬äººå¿—,ä¸‰è‹«,å¯¿å¸ãƒšãƒ­")
    print()


if __name__ == '__main__':
    main()
