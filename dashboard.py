#!/usr/bin/env python3
"""
ğŸ”¥ ç‚ä¸Šæ¤œçŸ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ GUIãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

Streamlitãƒ™ãƒ¼ã‚¹ã®æ“ä½œç”»é¢
- ãƒ‡ãƒ¼ã‚¿ç®¡ç†
- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
- çµæœå¯è¦–åŒ–
- ãƒ¢ãƒ‡ãƒ«å­¦ç¿’

Usage:
    streamlit run dashboard.py
"""

import streamlit as st
import pandas as pd
import subprocess
import sys
import time
from pathlib import Path
import json
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import yaml

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ğŸ”¥ ç‚ä¸Šæ¤œçŸ¥AI",
    page_icon="ğŸ”¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ãƒ‘ã‚¹è¨­å®š
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data"
STANDARDIZED_DIR = DATA_DIR / "standardized"
PROCESSED_DIR = DATA_DIR / "processed"
OUTPUTS_DIR = BASE_DIR / "modules" / "flame_detection" / "outputs"


def get_available_topics():
    """åˆ©ç”¨å¯èƒ½ãªãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§ã‚’å–å¾—"""
    topics = set()
    
    # standardized
    if STANDARDIZED_DIR.exists():
        for f in STANDARDIZED_DIR.glob("*.csv"):
            if not f.name.endswith("_meta.json"):
                topics.add(f.stem)
    
    # outputs (ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‚‚ã®)
    if OUTPUTS_DIR.exists():
        for d in OUTPUTS_DIR.iterdir():
            if d.is_dir() and (d / f"{d.name}_labeled.csv").exists():
                topics.add(d.name)
    
    return sorted(list(topics))


def get_topic_status(topic):
    """ãƒˆãƒ”ãƒƒã‚¯ã®å‡¦ç†çŠ¶æ³ã‚’ç¢ºèª"""
    status = {
        'standardized': (STANDARDIZED_DIR / f"{topic}.csv").exists(),
        'bert': (PROCESSED_DIR / f"{topic}_bert.csv").exists(),
        'sentiment': (PROCESSED_DIR / f"{topic}_sentiment_1h.csv").exists(),
        'stance': (BASE_DIR / "modules" / "stance_detection" / "outputs" / topic / f"{topic}_stance.csv").exists(),
        'feature': (BASE_DIR / "modules" / "feature_engineering" / "outputs" / topic / f"{topic}_feature_table.csv").exists(),
        'labeled': (OUTPUTS_DIR / topic / f"{topic}_labeled.csv").exists(),
        'model': (OUTPUTS_DIR / topic / "model" / "model.pkl").exists(),
        'label_config': (BASE_DIR / "modules" / "flame_detection" / f"label_config_{topic}.yaml").exists(),
    }
    return status


def run_pipeline_step_with_log(topic, steps, force=False, status_container=None):
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œï¼ˆã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«ãƒ­ã‚°å‡ºåŠ›ï¼‰"""
    cmd = f"python auto_pipeline.py {topic} --steps {steps}"
    if force:
        cmd += " --force"
    
    # ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«ã‚³ãƒãƒ³ãƒ‰ã‚’è¡¨ç¤º
    print(f"\n{'='*60}")
    print(f"ğŸ”¥ å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {cmd}")
    print(f"{'='*60}")
    sys.stdout.flush()
    
    if status_container:
        status_container.info(f"â³ å®Ÿè¡Œä¸­: `{cmd}`")
    
    # ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ­ã‚°ã‚’å‡ºåŠ›
    process = subprocess.Popen(
        cmd,
        shell=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        cwd=str(BASE_DIR),
        bufsize=1
    )
    
    output_lines = []
    for line in iter(process.stdout.readline, ''):
        output_lines.append(line)
        # ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«å‡ºåŠ›
        print(line, end='')
        sys.stdout.flush()
    
    process.wait()
    full_output = "".join(output_lines)
    
    print(f"\n{'='*60}")
    print(f"âœ… å®Œäº† (exit code: {process.returncode})")
    print(f"{'='*60}\n")
    sys.stdout.flush()
    
    return process.returncode == 0, full_output, ""


def run_unified_training_with_log(topics_str=None, status_container=None):
    """çµ±åˆå­¦ç¿’ã‚’å®Ÿè¡Œï¼ˆã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«ãƒ­ã‚°å‡ºåŠ›ï¼‰"""
    cmd = "python auto_pipeline.py --unified-train"
    if topics_str:
        cmd += f" --unified-topics {topics_str}"
    
    # ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«ã‚³ãƒãƒ³ãƒ‰ã‚’è¡¨ç¤º
    print(f"\n{'='*60}")
    print(f"ğŸ”¥ å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {cmd}")
    print(f"{'='*60}")
    sys.stdout.flush()
    
    if status_container:
        status_container.info(f"â³ å®Ÿè¡Œä¸­: `{cmd}`")
    
    # ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ­ã‚°ã‚’å‡ºåŠ›
    process = subprocess.Popen(
        cmd,
        shell=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        cwd=str(BASE_DIR),
        bufsize=1
    )
    
    output_lines = []
    for line in iter(process.stdout.readline, ''):
        output_lines.append(line)
        # ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«å‡ºåŠ›
        print(line, end='')
        sys.stdout.flush()
    
    process.wait()
    full_output = "".join(output_lines)
    
    print(f"\n{'='*60}")
    print(f"âœ… å®Œäº† (exit code: {process.returncode})")
    print(f"{'='*60}\n")
    sys.stdout.flush()
    
    return process.returncode == 0, full_output


def run_pipeline_step(topic, steps, force=False):
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰"""
    cmd = f"python auto_pipeline.py {topic} --steps {steps}"
    if force:
        cmd += " --force"
    
    result = subprocess.run(
        cmd, 
        shell=True, 
        capture_output=True, 
        text=True,
        cwd=str(BASE_DIR)
    )
    return result.returncode == 0, result.stdout, result.stderr


def load_feature_data(topic):
    """ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    path = BASE_DIR / "modules" / "feature_engineering" / "outputs" / topic / f"{topic}_feature_table.csv"
    if path.exists():
        return pd.read_csv(path)
    return None


def load_labeled_data(topic):
    """ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    path = OUTPUTS_DIR / topic / f"{topic}_labeled.csv"
    if path.exists():
        return pd.read_csv(path)
    return None


def load_label_config(topic):
    """ãƒ©ãƒ™ãƒ«è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
    path = BASE_DIR / "modules" / "flame_detection" / f"label_config_{topic}.yaml"
    if path.exists():
        with open(path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    return None


def save_label_config(topic, config):
    """ãƒ©ãƒ™ãƒ«è¨­å®šã‚’ä¿å­˜"""
    path = BASE_DIR / "modules" / "flame_detection" / f"label_config_{topic}.yaml"
    with open(path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, default_flow_style=False)


# ========================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# ========================================
st.sidebar.title("ğŸ”¥ ç‚ä¸Šæ¤œçŸ¥AI")
st.sidebar.markdown("---")

# ãƒšãƒ¼ã‚¸é¸æŠ
page = st.sidebar.radio(
    "ãƒšãƒ¼ã‚¸é¸æŠ",
    ["ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", "ğŸ”„ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ", "ğŸ·ï¸ ãƒ©ãƒ™ãƒªãƒ³ã‚°", "ğŸ¤– ãƒ¢ãƒ‡ãƒ«å­¦ç¿’", "ğŸ”¬ æ‰‹æ³•æ¯”è¼ƒ", "ğŸ“ˆ çµæœåˆ†æ"]
)

# ãƒˆãƒ”ãƒƒã‚¯é¸æŠ
topics = get_available_topics()
if topics:
    selected_topic = st.sidebar.selectbox("ãƒˆãƒ”ãƒƒã‚¯é¸æŠ", topics)
else:
    selected_topic = None
    st.sidebar.warning("ãƒˆãƒ”ãƒƒã‚¯ãŒã‚ã‚Šã¾ã›ã‚“")

st.sidebar.markdown("---")
st.sidebar.markdown("### ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®çµ±åˆå­¦ç¿’ãƒœã‚¿ãƒ³ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
if 'unified_training_result' not in st.session_state:
    st.session_state.unified_training_result = None

if st.sidebar.button("ğŸ”„ çµ±åˆå­¦ç¿’ã‚’å®Ÿè¡Œ"):
    # ç›´æ¥å®Ÿè¡Œï¼ˆãƒ­ã‚°ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«å‡ºåŠ›ï¼‰
    success, output = run_unified_training_with_log()
    st.session_state.unified_training_result = {"success": success, "output": output}
    st.rerun()


# ========================================
# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
# ========================================

if page == "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰":
    st.title("ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    
    # çµ±åˆå­¦ç¿’ã®çµæœè¡¨ç¤ºï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰å®Ÿè¡Œã•ã‚ŒãŸå ´åˆï¼‰
    if st.session_state.unified_training_result is not None:
        result = st.session_state.unified_training_result
        if result["success"]:
            st.success("âœ… çµ±åˆå­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        else:
            st.error("âŒ çµ±åˆå­¦ç¿’ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        st.session_state.unified_training_result = None
    
    # æ¦‚è¦
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ãƒˆãƒ”ãƒƒã‚¯æ•°", len(topics))
    
    # ãƒ©ãƒ™ãƒ«ä»˜ãæ¸ˆã¿ã‚«ã‚¦ãƒ³ãƒˆ
    labeled_count = sum(1 for t in topics if get_topic_status(t)['labeled'])
    with col2:
        st.metric("ãƒ©ãƒ™ãƒ«æ¸ˆã¿", labeled_count)
    
    # çµ±åˆãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹
    unified_model_exists = (OUTPUTS_DIR / "unified_model_v2" / "model.pkl").exists()
    with col3:
        st.metric("çµ±åˆãƒ¢ãƒ‡ãƒ«", "âœ… ã‚ã‚Š" if unified_model_exists else "âŒ ãªã—")
    
    # ç·ã‚µãƒ³ãƒ—ãƒ«æ•°
    total_samples = 0
    for t in topics:
        df = load_labeled_data(t)
        if df is not None:
            total_samples += len(df)
    with col4:
        st.metric("ç·ã‚µãƒ³ãƒ—ãƒ«æ•°", total_samples)
    
    st.markdown("---")
    
    # ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§
    st.subheader("ğŸ“‚ ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§")
    
    topic_data = []
    for t in topics:
        status = get_topic_status(t)
        df = load_labeled_data(t)
        
        topic_data.append({
            "ãƒˆãƒ”ãƒƒã‚¯": t,
            "æ¨™æº–åŒ–": "âœ…" if status['standardized'] else "âŒ",
            "æ„Ÿæƒ…åˆ†æ": "âœ…" if status['sentiment'] else "âŒ",
            "ç«‹å ´æ¤œå‡º": "âœ…" if status['stance'] else "âŒ",
            "ç‰¹å¾´é‡": "âœ…" if status['feature'] else "âŒ",
            "ãƒ©ãƒ™ãƒ«è¨­å®š": "âœ…" if status['label_config'] else "âŒ",
            "ãƒ©ãƒ™ãƒ«ä»˜ã": "âœ…" if status['labeled'] else "âŒ",
            "ã‚µãƒ³ãƒ—ãƒ«æ•°": len(df) if df is not None else 0,
            "ç‚ä¸Šç‡": f"{(df['is_controversy'].mean()*100):.1f}%" if df is not None and 'is_controversy' in df.columns else "-"
        })
    
    st.dataframe(pd.DataFrame(topic_data), use_container_width=True)
    
    # çµ±åˆãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½
    if unified_model_exists:
        st.markdown("---")
        st.subheader("ğŸ¤– çµ±åˆãƒ¢ãƒ‡ãƒ«æ€§èƒ½")
        
        metadata_path = OUTPUTS_DIR / "unified_model_v2" / "metadata.json"
        if metadata_path.exists():
            with open(metadata_path, 'r') as f:
                metadata = json.load(f)
            
            col1, col2, col3, col4 = st.columns(4)
            metrics = metadata.get('metrics', {})
            
            with col1:
                st.metric("CV Accuracy", f"{metrics.get('cv_accuracy_mean', 0)*100:.1f}%")
            with col2:
                st.metric("CV F1 Score", f"{metrics.get('cv_f1_mean', 0)*100:.1f}%")
            with col3:
                st.metric("CV ROC-AUC", f"{metrics.get('cv_roc_auc_mean', 0)*100:.1f}%")
            with col4:
                st.metric("ä½¿ç”¨ãƒˆãƒ”ãƒƒã‚¯æ•°", len(metadata.get('topics', [])))
            
            # ç‰¹å¾´é‡é‡è¦åº¦
            st.markdown("#### ç‰¹å¾´é‡é‡è¦åº¦")
            importance = metadata.get('feature_importance', {})
            if importance:
                fig = px.bar(
                    x=list(importance.values()),
                    y=list(importance.keys()),
                    orientation='h',
                    labels={'x': 'é‡è¦åº¦', 'y': 'ç‰¹å¾´é‡'}
                )
                fig.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})
                st.plotly_chart(fig, use_container_width=True)


elif page == "ğŸ”„ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ":
    st.title("ğŸ”„ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ")
    
    if selected_topic:
        status = get_topic_status(selected_topic)
        
        st.subheader(f"ğŸ“‚ {selected_topic} ã®å‡¦ç†çŠ¶æ³")
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
        cols = st.columns(6)
        steps_status = [
            ("æ¨™æº–åŒ–", status['standardized']),
            ("æ„Ÿæƒ…åˆ†æ", status['sentiment']),
            ("ç«‹å ´æ¤œå‡º", status['stance']),
            ("ç‰¹å¾´é‡", status['feature']),
            ("ãƒ©ãƒ™ãƒ«è¨­å®š", status['label_config']),
            ("ãƒ©ãƒ™ãƒ«ä»˜ã", status['labeled']),
        ]
        
        for col, (name, done) in zip(cols, steps_status):
            with col:
                if done:
                    st.success(f"âœ… {name}")
                else:
                    st.error(f"âŒ {name}")
        
        st.markdown("---")
        
        # å®Ÿè¡Œã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.subheader("âš™ï¸ å®Ÿè¡Œã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        col1, col2 = st.columns(2)
        
        with col1:
            selected_steps = st.multiselect(
                "å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—",
                ["combine", "sentiment", "stance", "feature", "label"],
                default=["sentiment", "stance", "feature"] if not status['feature'] else []
            )
        
        with col2:
            force = st.checkbox("å¼·åˆ¶ä¸Šæ›¸ã (--force)", value=False)
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºã‚¨ãƒªã‚¢
        status_area = st.empty()
        
        if st.button("ğŸš€ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ", type="primary", disabled=len(selected_steps)==0):
            steps_str = ",".join(selected_steps)
            
            st.info(f"â³ å®Ÿè¡Œä¸­: {steps_str}ï¼ˆãƒ­ã‚°ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«å‡ºåŠ›ã•ã‚Œã¾ã™ï¼‰")
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
            status_container = st.empty()
            success, stdout, _ = run_pipeline_step_with_log(
                selected_topic, steps_str, force, status_container
            )
            
            if success:
                st.success("âœ… å®Œäº†ã—ã¾ã—ãŸï¼")
            else:
                st.error("âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            
            # æœ€çµ‚ãƒ­ã‚°ã‚’å±•é–‹å¯èƒ½ãªå½¢å¼ã§è¡¨ç¤º
            with st.expander("ğŸ“‹ å®Ÿè¡Œãƒ­ã‚°", expanded=False):
                st.code(stdout, language="bash")
            
            time.sleep(1)
            st.rerun()
    else:
        st.warning("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠã—ã¦ãã ã•ã„")


elif page == "ğŸ·ï¸ ãƒ©ãƒ™ãƒªãƒ³ã‚°":
    st.title("ğŸ·ï¸ ãƒ©ãƒ™ãƒªãƒ³ã‚°è¨­å®š")
    
    if selected_topic:
        # ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
        df = load_feature_data(selected_topic)
        
        if df is not None:
            st.subheader("ğŸ“ˆ ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–")
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒ‘ãƒ¼ã‚¹
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # ã‚°ãƒ©ãƒ•ä½œæˆ
            fig = go.Figure()
            
            # æŠ•ç¨¿é‡
            fig.add_trace(go.Scatter(
                x=df['timestamp'],
                y=df['volume'],
                name='æŠ•ç¨¿é‡',
                yaxis='y'
            ))
            
            # ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡
            if 'negative_rate' in df.columns:
                fig.add_trace(go.Scatter(
                    x=df['timestamp'],
                    y=df['negative_rate'] * 100,
                    name='ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡ (%)',
                    yaxis='y2'
                ))
            
            fig.update_layout(
                title=f"{selected_topic} - æ™‚ç³»åˆ—æ¨ç§»",
                xaxis_title="æ—¥æ™‚",
                yaxis=dict(title="æŠ•ç¨¿é‡", side="left"),
                yaxis2=dict(title="ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡ (%)", side="right", overlaying="y"),
                height=400,
                hovermode='x unified'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # çµ±è¨ˆæƒ…å ±
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æœŸé–“", f"{df['timestamp'].min().strftime('%Y-%m-%d')} ã€œ {df['timestamp'].max().strftime('%Y-%m-%d')}")
            with col2:
                st.metric("æ™‚é–“æ•°", len(df))
            with col3:
                st.metric("å¹³å‡æŠ•ç¨¿é‡", f"{df['volume'].mean():.1f}")
            with col4:
                if 'negative_rate' in df.columns:
                    st.metric("å¹³å‡ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡", f"{df['negative_rate'].mean()*100:.1f}%")
            
            st.markdown("---")
            
            # ãƒ©ãƒ™ãƒ«è¨­å®š
            st.subheader("âš™ï¸ ç‚ä¸ŠæœŸé–“ã®è¨­å®š")
            
            # æ—¢å­˜è¨­å®šã‚’èª­ã¿è¾¼ã¿
            existing_config = load_label_config(selected_topic)
            
            if existing_config:
                st.info("æ—¢å­˜ã®è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                with st.expander("ç¾åœ¨ã®è¨­å®š", expanded=False):
                    st.code(yaml.dump(existing_config, allow_unicode=True))
            
            # ãƒ©ãƒ™ãƒ«è¨­å®š
            st.markdown("#### âš™ï¸ ãƒ©ãƒ™ãƒ«è¨­å®š")
            
            # ç‚ä¸Šãƒˆãƒ”ãƒƒã‚¯ã‹ã©ã†ã‹
            is_flame_topic = st.radio(
                "ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã¯ç‚ä¸Šäº‹ä¾‹ã§ã™ã‹ï¼Ÿ",
                ["ğŸ”¥ ç‚ä¸Šäº‹ä¾‹", "âœ… éç‚ä¸Šäº‹ä¾‹"],
                index=0,
                horizontal=True
            )
            
            if is_flame_topic == "ğŸ”¥ ç‚ä¸Šäº‹ä¾‹":
                st.markdown("##### ç‚ä¸ŠæœŸé–“ã®è¨­å®š")
                
                col1, col2 = st.columns(2)
                
                min_date = df['timestamp'].min().date()
                max_date = df['timestamp'].max().date()
                
                with col1:
                    st.markdown("**é–‹å§‹æ—¥æ™‚** (å¿…é ˆ)")
                    start_date = st.date_input("é–‹å§‹æ—¥", value=min_date, min_value=min_date, max_value=max_date, key="start_date")
                    start_hour = st.selectbox("é–‹å§‹æ™‚åˆ»", list(range(24)), index=0, key="start_hour")
                
                with col2:
                    st.markdown("**çµ‚äº†æ—¥æ™‚** (ä»»æ„)")
                    has_end_date = st.checkbox("çµ‚äº†æ—¥ã‚’è¨­å®šã™ã‚‹", value=True)
                    if has_end_date:
                        end_date = st.date_input("çµ‚äº†æ—¥", value=max_date, min_value=min_date, max_value=max_date, key="end_date")
                        end_hour = st.selectbox("çµ‚äº†æ™‚åˆ»", list(range(24)), index=23, key="end_hour")
                    else:
                        st.info("çµ‚äº†æ—¥æœªè¨­å®š â†’ ãƒ‡ãƒ¼ã‚¿çµ‚äº†ã¾ã§ç‚ä¸Šã¨ã¿ãªã™")
                        end_date = max_date
                        end_hour = 23
                
                description = st.text_input("èª¬æ˜ï¼ˆä»»æ„ï¼‰", placeholder="ä¾‹: æ–‡æ˜¥å ±é“å¾Œã®ç‚ä¸ŠæœŸé–“")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if st.button("ğŸ“ è¨­å®šã‚’ä¿å­˜", type="primary"):
                        start_str = f"{start_date} {start_hour:02d}:00:00"
                        end_str = f"{end_date} {end_hour:02d}:00:00"
                        
                        new_period = {
                            'start': start_str,
                            'end': end_str,
                        }
                        if description:
                            new_period['description'] = description
                        
                        config = {
                            'topic': selected_topic,
                            'controversy_periods': [new_period]
                        }
                        
                        save_label_config(selected_topic, config)
                        st.success("âœ… è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                        st.rerun()
                
                with col2:
                    if st.button("ğŸ·ï¸ ãƒ©ãƒ™ãƒªãƒ³ã‚°å®Ÿè¡Œ"):
                        if not get_topic_status(selected_topic)['label_config']:
                            st.error("å…ˆã«è¨­å®šã‚’ä¿å­˜ã—ã¦ãã ã•ã„")
                        else:
                            with st.spinner("ãƒ©ãƒ™ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­..."):
                                success, stdout, stderr = run_pipeline_step(selected_topic, "label", force=True)
                            
                            if success:
                                st.success("âœ… ãƒ©ãƒ™ãƒªãƒ³ã‚°å®Œäº†ï¼")
                                st.rerun()
                            else:
                                st.error("âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                                st.code(stderr if stderr else stdout)
                
                with col3:
                    if st.button("ğŸ—‘ï¸ è¨­å®šã‚’å‰Šé™¤"):
                        config = {
                            'topic': selected_topic,
                            'controversy_periods': []
                        }
                        save_label_config(selected_topic, config)
                        st.success("âœ… è¨­å®šã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                        st.rerun()
            
            else:
                # éç‚ä¸Šäº‹ä¾‹
                st.info("ğŸ“‹ éç‚ä¸Šäº‹ä¾‹ã¨ã—ã¦è¨­å®šã—ã¾ã™ï¼ˆå…¨æœŸé–“ is_controversy=0ï¼‰")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ“ éç‚ä¸Šã¨ã—ã¦ä¿å­˜", type="primary"):
                        config = {
                            'topic': selected_topic,
                            'controversy_periods': []
                        }
                        save_label_config(selected_topic, config)
                        st.success("âœ… éç‚ä¸Šã¨ã—ã¦è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                        st.rerun()
                
                with col2:
                    if st.button("ğŸ·ï¸ ãƒ©ãƒ™ãƒªãƒ³ã‚°å®Ÿè¡Œ"):
                        # è¨­å®šãŒãªãã¦ã‚‚éç‚ä¸Šã¨ã—ã¦å®Ÿè¡Œ
                        config = {
                            'topic': selected_topic,
                            'controversy_periods': []
                        }
                        save_label_config(selected_topic, config)
                        
                        with st.spinner("ãƒ©ãƒ™ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­..."):
                            success, stdout, stderr = run_pipeline_step(selected_topic, "label", force=True)
                        
                        if success:
                            st.success("âœ… ãƒ©ãƒ™ãƒªãƒ³ã‚°å®Œäº†ï¼ï¼ˆå…¨ã¦éç‚ä¸Šï¼‰")
                            st.rerun()
                        else:
                            st.error("âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                            st.code(stderr if stderr else stdout)
            
            # ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
            labeled_df = load_labeled_data(selected_topic)
            if labeled_df is not None:
                st.markdown("---")
                st.subheader("ğŸ“Š ãƒ©ãƒ™ãƒ«ä»˜ã‘çµæœ")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    controversy_count = (labeled_df['is_controversy'] == 1).sum()
                    st.metric("ç‚ä¸Šãƒ©ãƒ™ãƒ« (1)", controversy_count)
                with col2:
                    non_controversy_count = (labeled_df['is_controversy'] == 0).sum()
                    st.metric("éç‚ä¸Šãƒ©ãƒ™ãƒ« (0)", non_controversy_count)
                with col3:
                    total = len(labeled_df)
                    flame_rate = controversy_count / total * 100 if total > 0 else 0
                    st.metric("ç‚ä¸Šç‡", f"{flame_rate:.1f}%")
                
                # ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã®å¯è¦–åŒ–
                fig = px.pie(
                    values=[controversy_count, non_controversy_count],
                    names=['ç‚ä¸Š', 'éç‚ä¸Š'],
                    title='ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ'
                )
                st.plotly_chart(fig, use_container_width=True)
        
        else:
            st.warning("ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        st.warning("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠã—ã¦ãã ã•ã„")


elif page == "ğŸ¤– ãƒ¢ãƒ‡ãƒ«å­¦ç¿’":
    st.title("ğŸ¤– ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    
    # åˆ©ç”¨å¯èƒ½ãªãƒˆãƒ”ãƒƒã‚¯ï¼ˆãƒ©ãƒ™ãƒ«ä»˜ãæ¸ˆã¿ï¼‰
    labeled_topics = [t for t in topics if get_topic_status(t)['labeled']]
    
    st.subheader("ğŸ“‚ ãƒ©ãƒ™ãƒ«ä»˜ãæ¸ˆã¿ãƒˆãƒ”ãƒƒã‚¯")
    
    if labeled_topics:
        # ãƒˆãƒ”ãƒƒã‚¯æƒ…å ±
        topic_info = []
        for t in labeled_topics:
            df = load_labeled_data(t)
            if df is not None:
                topic_info.append({
                    'ãƒˆãƒ”ãƒƒã‚¯': t,
                    'ã‚µãƒ³ãƒ—ãƒ«æ•°': len(df),
                    'ç‚ä¸Š(1)': (df['is_controversy'] == 1).sum(),
                    'éç‚ä¸Š(0)': (df['is_controversy'] == 0).sum(),
                    'ç‚ä¸Šç‡': f"{df['is_controversy'].mean()*100:.1f}%"
                })
        
        st.dataframe(pd.DataFrame(topic_info), use_container_width=True)
        
        st.markdown("---")
        
        # çµ±åˆå­¦ç¿’
        st.subheader("ğŸš€ çµ±åˆå­¦ç¿’")
        
        selected_for_training = st.multiselect(
            "å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹ãƒˆãƒ”ãƒƒã‚¯",
            labeled_topics,
            default=labeled_topics
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ¤– çµ±åˆå­¦ç¿’ã‚’å®Ÿè¡Œ", type="primary", disabled=len(selected_for_training) < 2):
                topics_str = ",".join(selected_for_training)
                
                st.info(f"â³ çµ±åˆå­¦ç¿’ã‚’å®Ÿè¡Œä¸­: {topics_str}ï¼ˆãƒ­ã‚°ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«å‡ºåŠ›ã•ã‚Œã¾ã™ï¼‰")
                
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
                status_container = st.empty()
                success, output = run_unified_training_with_log(topics_str, status_container)
                
                if success:
                    st.success("âœ… çµ±åˆå­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                else:
                    st.error("âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                
                with st.expander("ğŸ“‹ å®Ÿè¡Œãƒ­ã‚°", expanded=False):
                    st.code(output, language="bash")
                
                time.sleep(1)
                st.rerun()
        
        with col2:
            if len(selected_for_training) < 2:
                st.warning("2ã¤ä»¥ä¸Šã®ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠã—ã¦ãã ã•ã„")
        
        # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        if (OUTPUTS_DIR / "unified_model_v2" / "metadata.json").exists():
            st.markdown("---")
            st.subheader("ğŸ“Š ç¾åœ¨ã®çµ±åˆãƒ¢ãƒ‡ãƒ«")
            
            with open(OUTPUTS_DIR / "unified_model_v2" / "metadata.json", 'r') as f:
                metadata = json.load(f)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ä½œæˆæ—¥æ™‚", metadata.get('created_at', '-')[:19])
            with col2:
                st.metric("ä½¿ç”¨ãƒˆãƒ”ãƒƒã‚¯", ", ".join(metadata.get('topics', [])))
            with col3:
                metrics = metadata.get('metrics', {})
                st.metric("CV F1 Score", f"{metrics.get('cv_f1_mean', 0)*100:.1f}%")
    
    else:
        st.warning("ãƒ©ãƒ™ãƒ«ä»˜ãæ¸ˆã¿ã®ãƒˆãƒ”ãƒƒã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")


elif page == "ğŸ”¬ æ‰‹æ³•æ¯”è¼ƒ":
    st.title("ğŸ”¬ æ„Ÿæƒ…åˆ†ææ‰‹æ³•ã®æ¯”è¼ƒå®Ÿé¨“")
    
    st.markdown("""
    ç•°ãªã‚‹æ„Ÿæƒ…åˆ†ææ‰‹æ³•ã‚’æ¯”è¼ƒã—ã¦ã€æœ€é©ãªæ‰‹æ³•ã‚’è¦‹ã¤ã‘ã¾ã™ã€‚
    
    ### æ¯”è¼ƒå¯¾è±¡
    | æ‰‹æ³• | èª¬æ˜ |
    |------|------|
    | **BERT ã®ã¿** | äº‹å‰å­¦ç¿’æ¸ˆã¿æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ„Ÿæƒ…åˆ†æ |
    | **è¾æ›¸ãƒ™ãƒ¼ã‚¹ ã®ã¿** | PNè¾æ›¸ã‚’ä½¿ç”¨ã—ãŸå¾“æ¥å‹ã®æ„Ÿæƒ…åˆ†æ |
    | **BERT + è¾æ›¸** | ä¸¡æ–¹ã®ç‰¹å¾´é‡ã‚’çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ |
    """)
    
    st.markdown("---")
    
    # ãƒ©ãƒ™ãƒ«ä»˜ãæ¸ˆã¿ãƒˆãƒ”ãƒƒã‚¯
    labeled_topics = [t for t in topics if get_topic_status(t)['labeled']]
    
    if len(labeled_topics) >= 2:
        st.subheader("ğŸ“‚ å®Ÿé¨“è¨­å®š")
        
        col1, col2 = st.columns(2)
        
        with col1:
            selected_for_comparison = st.multiselect(
                "æ¯”è¼ƒã«ä½¿ç”¨ã™ã‚‹ãƒˆãƒ”ãƒƒã‚¯",
                labeled_topics,
                default=labeled_topics
            )
        
        with col2:
            st.info(f"é¸æŠ: {len(selected_for_comparison)}ãƒˆãƒ”ãƒƒã‚¯")
        
        # è¾æ›¸åˆ†æã®äº‹å‰å®Ÿè¡Œã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.markdown("---")
        st.subheader("ğŸ“– è¾æ›¸ãƒ™ãƒ¼ã‚¹æ„Ÿæƒ…åˆ†æ")
        
        st.markdown("""
        è¾æ›¸ãƒ™ãƒ¼ã‚¹ã®æ¯”è¼ƒã‚’è¡Œã†ã«ã¯ã€äº‹å‰ã«è¾æ›¸æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
        """)
        
        # è¾æ›¸åˆ†æã®çŠ¶æ…‹ç¢ºèª
        dict_status = {}
        for t in selected_for_comparison:
            dict_path = PROCESSED_DIR / f"{t}_dict_sentiment_1h.csv"
            dict_status[t] = dict_path.exists()
        
        cols = st.columns(len(selected_for_comparison) if selected_for_comparison else 1)
        for i, t in enumerate(selected_for_comparison):
            with cols[i]:
                if dict_status[t]:
                    st.success(f"âœ… {t}")
                else:
                    st.warning(f"âŒ {t}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“– è¾æ›¸åˆ†æã‚’å®Ÿè¡Œ", type="secondary"):
                for topic in selected_for_comparison:
                    if not dict_status[topic]:
                        st.info(f"â³ {topic} ã®è¾æ›¸åˆ†æã‚’å®Ÿè¡Œä¸­...")
                        
                        # æ¨™æº–åŒ–CSVã‹ã‚‰è¾æ›¸åˆ†æï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ã‚’ä½¿ç”¨ï¼‰
                        input_path = STANDARDIZED_DIR / f"{topic}.csv"
                        output_path = PROCESSED_DIR / f"{topic}_dict_sentiment_1h.csv"
                        
                        # BASE_DIRã‹ã‚‰å®Ÿè¡Œã—ã€çµ¶å¯¾ãƒ‘ã‚¹ã‚’æ¸¡ã™
                        cmd = f"cd {BASE_DIR} && python modules/sentiment_analysis/aggregate_dict_sentiment.py {input_path} -o {output_path}"
                        
                        print(f"\n{'='*60}")
                        print(f"ğŸ”¥ å®Ÿè¡Œ: {cmd}")
                        print(f"{'='*60}")
                        sys.stdout.flush()
                        
                        import subprocess
                        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, cwd=str(BASE_DIR))
                        
                        if result.returncode == 0:
                            st.success(f"âœ… {topic} å®Œäº†")
                        else:
                            st.error(f"âŒ {topic} ã‚¨ãƒ©ãƒ¼")
                            st.code(result.stderr if result.stderr else result.stdout)
                
                time.sleep(1)
                st.rerun()
        
        # æ¯”è¼ƒå®Ÿé¨“å®Ÿè¡Œ
        st.markdown("---")
        st.subheader("ğŸ”¬ æ¯”è¼ƒå®Ÿé¨“")
        
        with col2:
            run_comparison = st.button("ğŸš€ æ¯”è¼ƒå®Ÿé¨“ã‚’å®Ÿè¡Œ", type="primary", 
                                       disabled=len(selected_for_comparison) < 2)
        
        if run_comparison:
            topics_str = ",".join(selected_for_comparison)
            
            st.info(f"â³ æ¯”è¼ƒå®Ÿé¨“ã‚’å®Ÿè¡Œä¸­...ï¼ˆãƒ­ã‚°ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«å‡ºåŠ›ã•ã‚Œã¾ã™ï¼‰")
            
            cmd = f"cd {BASE_DIR}/modules/flame_detection && python compare_sentiment_methods.py --topics {topics_str}"
            
            print(f"\n{'='*60}")
            print(f"ğŸ”¥ å®Ÿè¡Œ: {cmd}")
            print(f"{'='*60}")
            sys.stdout.flush()
            
            import subprocess
            process = subprocess.Popen(
                cmd, shell=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1
            )
            
            output_lines = []
            for line in iter(process.stdout.readline, ''):
                output_lines.append(line)
                print(line, end='')
                sys.stdout.flush()
            
            process.wait()
            
            if process.returncode == 0:
                st.success("âœ… æ¯”è¼ƒå®Ÿé¨“ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            else:
                st.error("âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            
            with st.expander("ğŸ“‹ å®Ÿè¡Œãƒ­ã‚°", expanded=True):
                st.code("".join(output_lines), language="bash")
            
            st.rerun()
        
        # éå»ã®çµæœã‚’è¡¨ç¤º
        st.markdown("---")
        st.subheader("ğŸ“Š æ¯”è¼ƒçµæœ")
        
        results_dir = OUTPUTS_DIR / "comparison_results"
        if results_dir.exists():
            result_files = sorted(results_dir.glob("sentiment_comparison_*.json"), reverse=True)
            
            if result_files:
                selected_result = st.selectbox(
                    "çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
                    result_files,
                    format_func=lambda x: x.stem
                )
                
                if selected_result:
                    with open(selected_result, 'r', encoding='utf-8') as f:
                        comparison_data = json.load(f)
                    
                    st.markdown(f"**å®Ÿè¡Œæ—¥æ™‚:** {comparison_data['timestamp']}")
                    st.markdown(f"**ä½¿ç”¨ãƒˆãƒ”ãƒƒã‚¯:** {', '.join(comparison_data['topics'])}")
                    st.markdown(f"**ã‚µãƒ³ãƒ—ãƒ«æ•°:** {comparison_data['n_samples']}")
                    
                    # çµæœãƒ†ãƒ¼ãƒ–ãƒ«
                    results_df = pd.DataFrame(comparison_data['results'])
                    
                    display_df = results_df[['method', 'cv_accuracy_mean', 'cv_f1_mean', 'cv_roc_auc_mean', 'n_features']].copy()
                    display_df.columns = ['æ‰‹æ³•', 'Accuracy', 'F1 Score', 'ROC-AUC', 'ç‰¹å¾´é‡æ•°']
                    display_df['Accuracy'] = display_df['Accuracy'].apply(lambda x: f"{x*100:.1f}%")
                    display_df['F1 Score'] = display_df['F1 Score'].apply(lambda x: f"{x*100:.1f}%")
                    display_df['ROC-AUC'] = display_df['ROC-AUC'].apply(lambda x: f"{x*100:.1f}%")
                    
                    st.dataframe(display_df, use_container_width=True)
                    
                    # ã‚°ãƒ©ãƒ•
                    fig = go.Figure()
                    
                    methods = results_df['method'].tolist()
                    
                    fig.add_trace(go.Bar(
                        name='Accuracy',
                        x=methods,
                        y=results_df['cv_accuracy_mean'] * 100,
                        text=[f"{v*100:.1f}%" for v in results_df['cv_accuracy_mean']],
                        textposition='auto',
                    ))
                    
                    fig.add_trace(go.Bar(
                        name='F1 Score',
                        x=methods,
                        y=results_df['cv_f1_mean'] * 100,
                        text=[f"{v*100:.1f}%" for v in results_df['cv_f1_mean']],
                        textposition='auto',
                    ))
                    
                    fig.add_trace(go.Bar(
                        name='ROC-AUC',
                        x=methods,
                        y=results_df['cv_roc_auc_mean'] * 100,
                        text=[f"{v*100:.1f}%" for v in results_df['cv_roc_auc_mean']],
                        textposition='auto',
                    ))
                    
                    fig.update_layout(
                        title='æ„Ÿæƒ…åˆ†ææ‰‹æ³•ã®æ¯”è¼ƒ',
                        xaxis_title='æ‰‹æ³•',
                        yaxis_title='ã‚¹ã‚³ã‚¢ (%)',
                        barmode='group',
                        height=400,
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # æœ€è‰¯æ‰‹æ³•
                    st.success(f"ğŸ† æœ€è‰¯æ‰‹æ³•: **{comparison_data['best_method']}**")
            else:
                st.info("ã¾ã æ¯”è¼ƒå®Ÿé¨“ã®çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šã®ãƒœã‚¿ãƒ³ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        else:
            st.info("ã¾ã æ¯”è¼ƒå®Ÿé¨“ã®çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šã®ãƒœã‚¿ãƒ³ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        
        # ========================================
        # ç«‹å ´æ¤œå‡ºã®æœ‰ç„¡ã®æ¯”è¼ƒ
        # ========================================
        st.markdown("---")
        st.markdown("---")
        st.subheader("ğŸ¯ ç«‹å ´æ¤œå‡ºã®æœ‰ç„¡ã®æ¯”è¼ƒ")
        
        st.markdown("""
        ç«‹å ´æ¤œå‡ºï¼ˆStance Detectionï¼‰ã®æœ‰ç„¡ãŒãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚
        
        | æ‰‹æ³• | èª¬æ˜ |
        |------|------|
        | **Stance ã‚ã‚Š** | æ„Ÿæƒ…åˆ†æ + ç«‹å ´æ¤œå‡ºï¼ˆè³›æˆ/åå¯¾/ä¸­ç«‹ï¼‰ã‚’ä½¿ç”¨ |
        | **Stance ãªã—** | æ„Ÿæƒ…åˆ†æã®ã¿ã‚’ä½¿ç”¨ï¼ˆç«‹å ´æ¤œå‡ºãªã—ï¼‰ |
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            run_stance_comparison = st.button("ğŸš€ ç«‹å ´æ¤œå‡ºæ¯”è¼ƒã‚’å®Ÿè¡Œ", type="primary",
                                              disabled=len(selected_for_comparison) < 2)
        
        if run_stance_comparison:
            topics_str = ",".join(selected_for_comparison)
            
            st.info(f"â³ ç«‹å ´æ¤œå‡ºæ¯”è¼ƒã‚’å®Ÿè¡Œä¸­...ï¼ˆãƒ­ã‚°ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«å‡ºåŠ›ã•ã‚Œã¾ã™ï¼‰")
            
            cmd = f"cd {BASE_DIR} && python modules/flame_detection/compare_sentiment_methods.py --topics {topics_str} --type stance"
            
            print(f"\n{'='*60}")
            print(f"ğŸ”¥ å®Ÿè¡Œ: {cmd}")
            print(f"{'='*60}")
            sys.stdout.flush()
            
            import subprocess
            process = subprocess.Popen(
                cmd, shell=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1
            )
            
            output_lines = []
            for line in iter(process.stdout.readline, ''):
                output_lines.append(line)
                print(line, end='')
                sys.stdout.flush()
            
            process.wait()
            
            if process.returncode == 0:
                st.success("âœ… ç«‹å ´æ¤œå‡ºæ¯”è¼ƒãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            else:
                st.error("âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            
            with st.expander("ğŸ“‹ å®Ÿè¡Œãƒ­ã‚°", expanded=True):
                st.code("".join(output_lines), language="bash")
            
            st.rerun()
        
        # ç«‹å ´æ¤œå‡ºæ¯”è¼ƒã®çµæœã‚’è¡¨ç¤º
        st.markdown("#### ğŸ“Š ç«‹å ´æ¤œå‡ºæ¯”è¼ƒã®çµæœ")
        
        if results_dir.exists():
            stance_result_files = sorted(results_dir.glob("stance_comparison_*.json"), reverse=True)
            
            if stance_result_files:
                selected_stance_result = st.selectbox(
                    "ç«‹å ´æ¤œå‡ºæ¯”è¼ƒã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
                    stance_result_files,
                    format_func=lambda x: x.stem,
                    key="stance_result_select"
                )
                
                if selected_stance_result:
                    with open(selected_stance_result, 'r', encoding='utf-8') as f:
                        stance_data = json.load(f)
                    
                    st.markdown(f"**å®Ÿè¡Œæ—¥æ™‚:** {stance_data['timestamp']}")
                    st.markdown(f"**ä½¿ç”¨ãƒˆãƒ”ãƒƒã‚¯:** {', '.join(stance_data['topics'])}")
                    
                    # çµæœãƒ†ãƒ¼ãƒ–ãƒ«
                    stance_results_df = pd.DataFrame(stance_data['results'])
                    
                    stance_display_df = stance_results_df[['method', 'cv_accuracy_mean', 'cv_f1_mean', 'cv_roc_auc_mean', 'n_features']].copy()
                    stance_display_df.columns = ['æ‰‹æ³•', 'Accuracy', 'F1 Score', 'ROC-AUC', 'ç‰¹å¾´é‡æ•°']
                    stance_display_df['Accuracy'] = stance_display_df['Accuracy'].apply(lambda x: f"{x*100:.1f}%")
                    stance_display_df['F1 Score'] = stance_display_df['F1 Score'].apply(lambda x: f"{x*100:.1f}%")
                    stance_display_df['ROC-AUC'] = stance_display_df['ROC-AUC'].apply(lambda x: f"{x*100:.1f}%")
                    
                    st.dataframe(stance_display_df, use_container_width=True)
                    
                    # ã‚°ãƒ©ãƒ•
                    fig2 = go.Figure()
                    
                    stance_methods = stance_results_df['method'].tolist()
                    
                    fig2.add_trace(go.Bar(
                        name='Accuracy',
                        x=stance_methods,
                        y=stance_results_df['cv_accuracy_mean'] * 100,
                        text=[f"{v*100:.1f}%" for v in stance_results_df['cv_accuracy_mean']],
                        textposition='auto',
                    ))
                    
                    fig2.add_trace(go.Bar(
                        name='F1 Score',
                        x=stance_methods,
                        y=stance_results_df['cv_f1_mean'] * 100,
                        text=[f"{v*100:.1f}%" for v in stance_results_df['cv_f1_mean']],
                        textposition='auto',
                    ))
                    
                    fig2.add_trace(go.Bar(
                        name='ROC-AUC',
                        x=stance_methods,
                        y=stance_results_df['cv_roc_auc_mean'] * 100,
                        text=[f"{v*100:.1f}%" for v in stance_results_df['cv_roc_auc_mean']],
                        textposition='auto',
                    ))
                    
                    fig2.update_layout(
                        title='ç«‹å ´æ¤œå‡ºã®æœ‰ç„¡ã®æ¯”è¼ƒ',
                        xaxis_title='æ‰‹æ³•',
                        yaxis_title='ã‚¹ã‚³ã‚¢ (%)',
                        barmode='group',
                        height=400,
                    )
                    
                    st.plotly_chart(fig2, use_container_width=True)
                    
                    # åŠ¹æœã®è¡¨ç¤º
                    with_stance = next((r for r in stance_data['results'] if r['method_key'] == 'with_stance'), None)
                    without_stance = next((r for r in stance_data['results'] if r['method_key'] == 'without_stance'), None)
                    
                    if with_stance and without_stance:
                        diff_f1 = (with_stance['cv_f1_mean'] - without_stance['cv_f1_mean']) * 100
                        diff_auc = (with_stance['cv_roc_auc_mean'] - without_stance['cv_roc_auc_mean']) * 100
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("F1 Score æ”¹å–„", f"{'+' if diff_f1 >= 0 else ''}{diff_f1:.1f}%",
                                     delta=f"{diff_f1:.1f}%")
                        with col2:
                            st.metric("ROC-AUC æ”¹å–„", f"{'+' if diff_auc >= 0 else ''}{diff_auc:.1f}%",
                                     delta=f"{diff_auc:.1f}%")
                    
                    st.success(f"ğŸ† æœ€è‰¯æ‰‹æ³•: **{stance_data['best_method']}**")
            else:
                st.info("ã¾ã ç«‹å ´æ¤œå‡ºæ¯”è¼ƒã®çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šã®ãƒœã‚¿ãƒ³ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        else:
            st.info("ã¾ã ç«‹å ´æ¤œå‡ºæ¯”è¼ƒã®çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šã®ãƒœã‚¿ãƒ³ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    else:
        st.warning("æ¯”è¼ƒå®Ÿé¨“ã«ã¯2ã¤ä»¥ä¸Šã®ãƒ©ãƒ™ãƒ«ä»˜ãæ¸ˆã¿ãƒˆãƒ”ãƒƒã‚¯ãŒå¿…è¦ã§ã™ã€‚å…ˆã«ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")


elif page == "ğŸ“ˆ çµæœåˆ†æ":
    st.title("ğŸ“ˆ çµæœåˆ†æ")
    
    if selected_topic:
        labeled_df = load_labeled_data(selected_topic)
        
        if labeled_df is not None:
            st.subheader(f"ğŸ“Š {selected_topic} ã®åˆ†æ")
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒ‘ãƒ¼ã‚¹
            labeled_df['timestamp'] = pd.to_datetime(labeled_df['timestamp'])
            
            # æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•
            fig = go.Figure()
            
            # ç‚ä¸ŠæœŸé–“ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            controversy_periods = labeled_df[labeled_df['is_controversy'] == 1]
            if len(controversy_periods) > 0:
                for _, row in controversy_periods.iterrows():
                    fig.add_vrect(
                        x0=row['timestamp'],
                        x1=row['timestamp'] + pd.Timedelta(hours=1),
                        fillcolor="red",
                        opacity=0.2,
                        line_width=0,
                    )
            
            # æŠ•ç¨¿é‡
            fig.add_trace(go.Scatter(
                x=labeled_df['timestamp'],
                y=labeled_df['volume'],
                name='æŠ•ç¨¿é‡',
                line=dict(color='blue')
            ))
            
            # ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡
            if 'negative_rate' in labeled_df.columns:
                fig.add_trace(go.Scatter(
                    x=labeled_df['timestamp'],
                    y=labeled_df['negative_rate'] * 100,
                    name='ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡ (%)',
                    yaxis='y2',
                    line=dict(color='orange')
                ))
            
            fig.update_layout(
                title=f"{selected_topic} - æ™‚ç³»åˆ—æ¨ç§»ï¼ˆèµ¤ï¼šç‚ä¸ŠæœŸé–“ï¼‰",
                xaxis_title="æ—¥æ™‚",
                yaxis=dict(title="æŠ•ç¨¿é‡", side="left"),
                yaxis2=dict(title="ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡ (%)", side="right", overlaying="y"),
                height=500,
                hovermode='x unified'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # çµ±è¨ˆ
            st.markdown("---")
            st.subheader("ğŸ“Š çµ±è¨ˆæƒ…å ±")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ç‚ä¸ŠæœŸé–“ (is_controversy=1)")
                controversy = labeled_df[labeled_df['is_controversy'] == 1]
                if len(controversy) > 0:
                    st.write(f"- ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(controversy)}")
                    st.write(f"- å¹³å‡æŠ•ç¨¿é‡: {controversy['volume'].mean():.1f}")
                    if 'negative_rate' in controversy.columns:
                        st.write(f"- å¹³å‡ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡: {controversy['negative_rate'].mean()*100:.1f}%")
                else:
                    st.write("ãƒ‡ãƒ¼ã‚¿ãªã—")
            
            with col2:
                st.markdown("#### éç‚ä¸ŠæœŸé–“ (is_controversy=0)")
                non_controversy = labeled_df[labeled_df['is_controversy'] == 0]
                if len(non_controversy) > 0:
                    st.write(f"- ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(non_controversy)}")
                    st.write(f"- å¹³å‡æŠ•ç¨¿é‡: {non_controversy['volume'].mean():.1f}")
                    if 'negative_rate' in non_controversy.columns:
                        st.write(f"- å¹³å‡ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡: {non_controversy['negative_rate'].mean()*100:.1f}%")
                else:
                    st.write("ãƒ‡ãƒ¼ã‚¿ãªã—")
            
            # ç‰¹å¾´é‡ã®ç®±ã²ã’å›³
            st.markdown("---")
            st.subheader("ğŸ“Š ç‰¹å¾´é‡æ¯”è¼ƒ")
            
            feature_cols = ['volume', 'negative_rate', 'stance_against_rate']
            available_features = [f for f in feature_cols if f in labeled_df.columns]
            
            if available_features:
                selected_feature = st.selectbox("ç‰¹å¾´é‡ã‚’é¸æŠ", available_features)
                
                fig = px.box(
                    labeled_df,
                    x='is_controversy',
                    y=selected_feature,
                    labels={'is_controversy': 'ãƒ©ãƒ™ãƒ«', selected_feature: selected_feature},
                    title=f'{selected_feature} ã®åˆ†å¸ƒæ¯”è¼ƒ'
                )
                fig.update_xaxes(ticktext=['éç‚ä¸Š (0)', 'ç‚ä¸Š (1)'], tickvals=[0, 1])
                st.plotly_chart(fig, use_container_width=True)
        
        else:
            st.warning("ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
    else:
        st.warning("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠã—ã¦ãã ã•ã„")


# ãƒ•ãƒƒã‚¿ãƒ¼
st.sidebar.markdown("---")
st.sidebar.markdown("v2.0 | ğŸ”¥ ç‚ä¸Šæ¤œçŸ¥AI")
