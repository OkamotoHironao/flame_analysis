#!/usr/bin/env python3
"""
Stance Detection æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ãƒ„ã‚¤ãƒ¼ãƒˆã®ç«‹å ´ã‚’åˆ†é¡
"""

import os
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import torch
import pandas as pd
from tqdm import tqdm
from transformers import AutoTokenizer
import json
import torch.nn as nn
from transformers import AutoModel

from modules.stance_detection.dataset import StanceDataset


# ãƒ¢ãƒ‡ãƒ«å®šç¾©
class StanceClassifier(nn.Module):
    def __init__(self, model_name, num_labels=3, dropout=0.3):
        super(StanceClassifier, self).__init__()
        self.bert = AutoModel.from_pretrained(model_name)
        self.dropout = nn.Dropout(dropout)
        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)
    
    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output
        pooled_output = self.dropout(pooled_output)
        logits = self.classifier(pooled_output)
        return logits


def load_model(model_dir, device):
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    config_path = Path(model_dir) / "config.json"
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    model = StanceClassifier(
        config['model_name'],
        num_labels=config['num_labels'],
        dropout=config['dropout']
    )
    
    model.load_state_dict(torch.load(
        Path(model_dir) / "best_model.pth",
        map_location=device
    ))
    model.to(device)
    model.eval()
    
    return model, config


def predict(model, dataloader, device):
    """æ¨è«–å®Ÿè¡Œ"""
    all_predictions = []
    all_probabilities = []
    
    model.eval()
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="ğŸ” æ¨è«–ä¸­"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            
            logits = model(input_ids, attention_mask)
            probs = torch.nn.functional.softmax(logits, dim=-1)
            
            _, predicted = torch.max(logits, 1)
            
            all_predictions.extend(predicted.cpu().numpy())
            all_probabilities.extend(probs.cpu().numpy())
    
    return all_predictions, all_probabilities


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
    script_dir = Path(__file__).parent
    os.chdir(script_dir)
    
    if len(sys.argv) != 3:
        print("ä½¿ç”¨æ³•: python predict.py <input_csv> <output_csv>")
        print("ä¾‹: python predict.py ../../data/original/tweets_æ¾æœ¬äººå¿—.csv outputs/predictions.csv")
        sys.exit(1)
    
    input_path = sys.argv[1]
    output_path = sys.argv[2]
    
    print("=" * 60)
    print("Stance Detection æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    
    MODEL_DIR = "model"
    BATCH_SIZE = 32
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  ãƒ‡ãƒã‚¤ã‚¹: {device}")
    
    if not Path(input_path).exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
        sys.exit(1)
    
    if not Path(MODEL_DIR).exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {MODEL_DIR}")
        print("å…ˆã« train.py ã§å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)
    
    try:
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        print(f"\nğŸ¤– ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­: {MODEL_DIR}")
        model, config = load_model(MODEL_DIR, device)
        tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
        print("âœ“ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        print(f"\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {input_path}")
        df = pd.read_csv(input_path, comment='#')
        print(f"âœ“ {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        
        # ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã®ç¢ºèª
        if 'content' not in df.columns:
            if 'text' in df.columns:
                df['content'] = df['text']
            else:
                raise ValueError("âŒ 'content' ã¾ãŸã¯ 'text' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        texts = df['content'].fillna("").tolist()
        dataset = StanceDataset(texts, None, tokenizer, config['max_length'])
        dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)
        
        # æ¨è«–å®Ÿè¡Œ
        print(f"\nğŸ” æ¨è«–å®Ÿè¡Œä¸­...")
        predictions, probabilities = predict(model, dataloader, device)
        
        # ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°
        LABEL_MAP = {0: "AGAINST", 1: "FAVOR", 2: "NEUTRAL"}
        
        # çµæœã‚’DataFrameã«è¿½åŠ 
        df['stance_label'] = [LABEL_MAP[pred] for pred in predictions]
        df['stance_against'] = [prob[0] for prob in probabilities]
        df['stance_favor'] = [prob[1] for prob in probabilities]
        df['stance_neutral'] = [prob[2] for prob in probabilities]
        
        # çµ±è¨ˆæƒ…å ±
        label_counts = df['stance_label'].value_counts()
        print(f"\nâœ“ æ¨è«–å®Œäº†:")
        for label, count in label_counts.items():
            percentage = (count / len(df)) * 100
            print(f"  - {label}: {count}ä»¶ ({percentage:.1f}%)")
        
        # çµæœä¿å­˜
        output_dir = Path(output_path).parent
        if output_dir != Path('.'):
            output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ä¸­: {output_path}")
        df.to_csv(output_path, index=False)
        print("âœ“ ä¿å­˜å®Œäº†")
        
        print("\n" + "=" * 60)
        print("âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
