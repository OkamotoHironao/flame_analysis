#!/usr/bin/env python3
"""
ç‰¹å¾´é‡çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆFeature Builderï¼‰
æ„Ÿæƒ…åˆ†æã¨ç«‹å ´åˆ†é¡ã®çµæœã‚’çµ±åˆã—ã€ç‚ä¸Šåˆ¤å®šç”¨ã®ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”Ÿæˆ
"""

import sys
import os
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import pandas as pd
import argparse
from datetime import datetime
from tqdm import tqdm


def extract_query_name(filepath):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«åã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‹ã‚‰ã‚¯ã‚¨ãƒªåã‚’æŠ½å‡º
    
    Args:
        filepath: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
    Returns:
        str: ã‚¯ã‚¨ãƒªåï¼ˆä¾‹: "æ¾æœ¬äººå¿—"ï¼‰
    """
    path = Path(filepath)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‹ã‚‰æŠ½å‡ºï¼ˆdata/original/æ¾æœ¬äººå¿—/ ãªã©ï¼‰
    if 'original' in path.parts:
        original_idx = path.parts.index('original')
        if original_idx + 1 < len(path.parts):
            potential_query = path.parts[original_idx + 1]
            # ãƒ•ã‚¡ã‚¤ãƒ«åã§ãªã‘ã‚Œã°ã‚¯ã‚¨ãƒªåã¨ã—ã¦æ¡ç”¨
            if not potential_query.endswith('.csv'):
                return potential_query
    
    # outputsé…ä¸‹ã®å ´åˆï¼ˆoutputs/æ¾æœ¬äººå¿—/ ãªã©ï¼‰
    if 'outputs' in path.parts:
        outputs_idx = path.parts.index('outputs')
        if outputs_idx + 1 < len(path.parts):
            potential_query = path.parts[outputs_idx + 1]
            # ãƒ•ã‚¡ã‚¤ãƒ«åã§ãªã‘ã‚Œã°ã‚¯ã‚¨ãƒªåã¨ã—ã¦æ¡ç”¨
            if not potential_query.endswith('.csv'):
                return potential_query
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æŠ½å‡ºï¼ˆæ¾æœ¬äººå¿—_*.csvï¼‰
    filename = path.stem
    # ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
    for suffix in ['_sentiment_1h', '_sentiment_30m', '_sentiment_10m', '_stance', '_analyzed', '_bert', '_feature_table']:
        if filename.endswith(suffix):
            filename = filename[:-len(suffix)]
            break
    
    # æ®‹ã‚Šã®éƒ¨åˆ†ã‹ã‚‰ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆæ•°å­—ã®ã¿ï¼‰ã‚’é™¤å»
    parts = filename.split('_')
    query_parts = [p for p in parts if not p.isdigit()]
    
    return '_'.join(query_parts) if query_parts else "unknown"


def load_sentiment_timeseries(csv_path):
    """
    æ™‚ç³»åˆ—åŒ–æ¸ˆã¿ã®æ„Ÿæƒ…åˆ†æçµæœã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        csv_path: æ„Ÿæƒ…åˆ†æCSVã®ãƒ‘ã‚¹
        
    Returns:
        pd.DataFrame: æ„Ÿæƒ…åˆ†æã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿
    """
    print(f"\nğŸ“Š æ„Ÿæƒ…åˆ†æãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {csv_path}")
    
    df = pd.read_csv(csv_path, comment='#')
    
    # timestampåˆ—ã‚’datetimeã«å¤‰æ›
    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'])
    elif 'time' in df.columns:
        df['timestamp'] = pd.to_datetime(df['time'])
    else:
        raise ValueError("æ„Ÿæƒ…åˆ†æCSVã« 'timestamp' ã¾ãŸã¯ 'time' åˆ—ãŒå¿…è¦ã§ã™")
    
    # å¿…è¦ãªåˆ—ã‚’ç¢ºèª
    required_cols = ['timestamp', 'count', 'negative_rate']
    for col in required_cols:
        if col not in df.columns:
            raise ValueError(f"æ„Ÿæƒ…åˆ†æCSVã« '{col}' åˆ—ãŒå¿…è¦ã§ã™")
    
    # avg_scoreåˆ—ãŒãªã„å ´åˆã¯0ã§åŸ‹ã‚ã‚‹
    if 'avg_score' not in df.columns:
        df['avg_score'] = 0.0
    
    print(f"âœ“ {len(df)}ä»¶ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    print(f"  æœŸé–“: {df['timestamp'].min()} ã€œ {df['timestamp'].max()}")
    
    return df[['timestamp', 'count', 'avg_score', 'negative_rate']]


def load_and_aggregate_stance(csv_path):
    """
    ç«‹å ´åˆ†é¡çµæœã‚’èª­ã¿è¾¼ã¿ã€1æ™‚é–“ã”ã¨ã«é›†è¨ˆ
    
    Args:
        csv_path: ç«‹å ´åˆ†é¡CSVã®ãƒ‘ã‚¹
        
    Returns:
        pd.DataFrame: 1æ™‚é–“ã”ã¨ã«é›†è¨ˆã•ã‚ŒãŸç«‹å ´åˆ†é¡ãƒ‡ãƒ¼ã‚¿
    """
    print(f"\nğŸ¯ ç«‹å ´åˆ†é¡ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {csv_path}")
    
    df = pd.read_csv(csv_path, comment='#')
    
    # æ—¥æ™‚åˆ—ã®ç¢ºèª
    date_col = None
    for col in ['created_at', 'date', 'timestamp']:
        if col in df.columns:
            date_col = col
            break
    
    if date_col is None:
        raise ValueError("ç«‹å ´åˆ†é¡CSVã« 'created_at', 'date', ã¾ãŸã¯ 'timestamp' åˆ—ãŒå¿…è¦ã§ã™")
    
    # datetimeå¤‰æ›
    df['timestamp'] = pd.to_datetime(df[date_col])
    
    # 1æ™‚é–“å˜ä½ã«ä¸¸ã‚ã‚‹ï¼ˆåºŠåˆ‡ã‚Šï¼‰
    df['timestamp'] = df['timestamp'].dt.floor('h')
    
    print(f"âœ“ {len(df)}ä»¶ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    print(f"  æœŸé–“: {df['timestamp'].min()} ã€œ {df['timestamp'].max()}")
    
    # ç«‹å ´ãƒ©ãƒ™ãƒ«ã®ç¢ºèª
    if 'stance_label' not in df.columns:
        raise ValueError("ç«‹å ´åˆ†é¡CSVã« 'stance_label' åˆ—ãŒå¿…è¦ã§ã™")
    
    print(f"\nğŸ“ˆ 1æ™‚é–“ã”ã¨ã«é›†è¨ˆä¸­...")
    
    # æ™‚é–“ã”ã¨ã«é›†è¨ˆ
    aggregated_data = []
    
    for timestamp, group in tqdm(df.groupby('timestamp'), desc="é›†è¨ˆä¸­"):
        total = len(group)
        
        # ç«‹å ´ã®å‰²åˆã‚’è¨ˆç®—
        stance_counts = group['stance_label'].value_counts()
        against_count = stance_counts.get('AGAINST', 0)
        favor_count = stance_counts.get('FAVOR', 0)
        neutral_count = stance_counts.get('NEUTRAL', 0)
        
        # ç¢ºç‡ã®å¹³å‡ã‚’è¨ˆç®—ï¼ˆåˆ—ãŒã‚ã‚‹å ´åˆï¼‰
        against_mean = group['stance_against'].mean() if 'stance_against' in group.columns else 0.0
        favor_mean = group['stance_favor'].mean() if 'stance_favor' in group.columns else 0.0
        neutral_mean = group['stance_neutral'].mean() if 'stance_neutral' in group.columns else 0.0
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™ã‚’é›†è¨ˆ
        avg_like = group['like_count'].mean() if 'like_count' in group.columns else 0.0
        avg_retweet = group['retweet_count'].mean() if 'retweet_count' in group.columns else 0.0
        avg_reply = group['reply_count'].mean() if 'reply_count' in group.columns else 0.0
        
        max_like = group['like_count'].max() if 'like_count' in group.columns else 0.0
        max_retweet = group['retweet_count'].max() if 'retweet_count' in group.columns else 0.0
        max_reply = group['reply_count'].max() if 'reply_count' in group.columns else 0.0
        
        total_like = group['like_count'].sum() if 'like_count' in group.columns else 0.0
        total_retweet = group['retweet_count'].sum() if 'retweet_count' in group.columns else 0.0
        total_reply = group['reply_count'].sum() if 'reply_count' in group.columns else 0.0
        
        aggregated_data.append({
            'timestamp': timestamp,
            'stance_against_rate': against_count / total if total > 0 else 0.0,
            'stance_favor_rate': favor_count / total if total > 0 else 0.0,
            'stance_neutral_rate': neutral_count / total if total > 0 else 0.0,
            'stance_against_mean': against_mean,
            'stance_favor_mean': favor_mean,
            'stance_neutral_mean': neutral_mean,
            'stance_count': total,
            'avg_like_count': avg_like,
            'avg_retweet_count': avg_retweet,
            'avg_reply_count': avg_reply,
            'max_like_count': max_like,
            'max_retweet_count': max_retweet,
            'max_reply_count': max_reply,
            'total_like_count': total_like,
            'total_retweet_count': total_retweet,
            'total_reply_count': total_reply
        })
    
    result = pd.DataFrame(aggregated_data)
    print(f"âœ“ {len(result)}å€‹ã®æ™‚é–“æ ã«é›†è¨ˆã—ã¾ã—ãŸ")
    
    return result


def create_features(sentiment_df, stance_df):
    """
    æ„Ÿæƒ…åˆ†æã¨ç«‹å ´åˆ†é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã€ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
    
    Args:
        sentiment_df: æ„Ÿæƒ…åˆ†æã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿
        stance_df: ç«‹å ´åˆ†é¡ã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿
        
    Returns:
        pd.DataFrame: ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«
    """
    print(f"\nğŸ”§ ç‰¹å¾´é‡ç”Ÿæˆä¸­...")
    
    # timestamp ã‚’ã‚­ãƒ¼ã«ã—ã¦çµåˆ
    df = pd.merge(
        sentiment_df,
        stance_df,
        on='timestamp',
        how='outer'
    )
    
    # timestamp ã§ã‚½ãƒ¼ãƒˆ
    df = df.sort_values('timestamp').reset_index(drop=True)
    
    # åŸºæœ¬ç‰¹å¾´é‡
    df['volume'] = df['count'].fillna(0)
    df['sentiment_avg_score'] = df['avg_score'].fillna(0)
    
    # æ¬ æå€¤ã‚’0ã§åŸ‹ã‚ã‚‹
    fill_cols = [
        'negative_rate', 
        'stance_against_rate', 
        'stance_favor_rate',
        'stance_neutral_rate',
        'stance_against_mean',
        'stance_favor_mean',
        'stance_neutral_mean'
    ]
    for col in fill_cols:
        if col in df.columns:
            df[col] = df[col].fillna(0)
    
    # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆè¤‡åˆç‰¹å¾´é‡
    if 'avg_like_count' in df.columns:
        df['avg_engagement'] = df['avg_like_count'] + df['avg_retweet_count'] + df['avg_reply_count']
        df['total_engagement'] = df['total_like_count'] + df['total_retweet_count'] + df['total_reply_count']
        df['max_engagement'] = df[['max_like_count', 'max_retweet_count', 'max_reply_count']].max(axis=1)
        df['engagement_rate'] = (df['total_engagement'] / df['volume']).fillna(0).replace([float('inf'), float('-inf')], 0)
    else:
        df['avg_engagement'] = 0
        df['total_engagement'] = 0
        df['max_engagement'] = 0
        df['engagement_rate'] = 0
    
    # å·®åˆ†ç‰¹å¾´é‡ï¼ˆå‰æ™‚é–“ã¨ã®å·®ï¼‰
    df['delta_volume'] = df['volume'].diff().fillna(0)
    df['delta_negative_rate'] = df['negative_rate'].diff().fillna(0)
    df['delta_against_rate'] = df['stance_against_rate'].diff().fillna(0)
    df['delta_engagement'] = df['total_engagement'].diff().fillna(0)
    
    # å¤‰åŒ–ç‡ç‰¹å¾´é‡ï¼ˆå‰æ™‚é–“æ¯”ï¼‰
    df['delta_volume_rate'] = (df['delta_volume'] / df['volume'].shift(1)).fillna(0)
    df['delta_volume_rate'] = df['delta_volume_rate'].replace([float('inf'), float('-inf')], 0)
    df['delta_engagement_rate'] = (df['delta_engagement'] / df['total_engagement'].shift(1)).fillna(0)
    df['delta_engagement_rate'] = df['delta_engagement_rate'].replace([float('inf'), float('-inf')], 0)
    
    # æœ€çµ‚çš„ãªç‰¹å¾´é‡åˆ—ã‚’é¸æŠ
    feature_cols = [
        'timestamp',
        'volume',
        'negative_rate',
        'stance_against_rate',
        'stance_favor_rate',
        'stance_neutral_rate',
        'delta_volume',
        'delta_negative_rate',
        'delta_against_rate',
        'delta_volume_rate',
        'sentiment_avg_score',
        'stance_against_mean',
        'stance_favor_mean',
        'stance_neutral_mean',
        'avg_engagement',
        'total_engagement',
        'max_engagement',
        'engagement_rate',
        'delta_engagement',
        'delta_engagement_rate',
        'avg_like_count',
        'avg_retweet_count',
        'avg_reply_count'
    ]
    
    # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿é¸æŠ
    existing_cols = [col for col in feature_cols if col in df.columns]
    df = df[existing_cols]
    
    print(f"âœ“ {len(df)}ä»¶ã®ç‰¹å¾´é‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    
    return df


def print_statistics(df):
    """
    çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    
    Args:
        df: ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«
    """
    print(f"\n{'='*60}")
    print("ğŸ“Š ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆ")
    print(f"{'='*60}")
    
    print(f"\nğŸ“ˆ åŸºæœ¬æƒ…å ±:")
    print(f"  ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df)}ä»¶")
    print(f"  æœŸé–“: {df['timestamp'].min()} ã€œ {df['timestamp'].max()}")
    
    print(f"\nğŸ“Š å¹³å‡å€¤:")
    if 'volume' in df.columns:
        print(f"  å¹³å‡æŠ•ç¨¿æ•°: {df['volume'].mean():.2f}ä»¶/æ™‚é–“")
    if 'negative_rate' in df.columns:
        print(f"  å¹³å‡ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡: {df['negative_rate'].mean():.2%}")
    if 'stance_against_rate' in df.columns:
        print(f"  å¹³å‡AGAINSTç‡: {df['stance_against_rate'].mean():.2%}")
    if 'stance_favor_rate' in df.columns:
        print(f"  å¹³å‡FAVORç‡: {df['stance_favor_rate'].mean():.2%}")
    
    print(f"\nğŸš€ æœ€å¤§å€¤:")
    if 'volume' in df.columns:
        max_volume_idx = df['volume'].idxmax()
        print(f"  æœ€å¤§æŠ•ç¨¿æ•°: {df.loc[max_volume_idx, 'volume']:.0f}ä»¶ ({df.loc[max_volume_idx, 'timestamp']})")
    
    if 'delta_volume' in df.columns:
        max_delta_idx = df['delta_volume'].idxmax()
        print(f"  æœ€å¤§æŠ•ç¨¿æ€¥å¢—: +{df.loc[max_delta_idx, 'delta_volume']:.0f}ä»¶ ({df.loc[max_delta_idx, 'timestamp']})")
    
    if 'delta_volume_rate' in df.columns:
        max_rate_idx = df['delta_volume_rate'].idxmax()
        max_rate = df.loc[max_rate_idx, 'delta_volume_rate']
        if max_rate > 0:
            print(f"  æœ€å¤§æŠ•ç¨¿æ€¥å¢—ç‡: {max_rate:.1%} ({df.loc[max_rate_idx, 'timestamp']})")
    
    if 'negative_rate' in df.columns:
        max_neg_idx = df['negative_rate'].idxmax()
        print(f"  æœ€å¤§ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡: {df.loc[max_neg_idx, 'negative_rate']:.1%} ({df.loc[max_neg_idx, 'timestamp']})")
    
    print(f"\n{'='*60}")


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    parser = argparse.ArgumentParser(
        description='æ„Ÿæƒ…åˆ†æã¨ç«‹å ´åˆ†é¡ã®çµæœã‚’çµ±åˆã—ã€ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”Ÿæˆ'
    )
    parser.add_argument(
        '--sentiment_csv',
        required=True,
        help='æ„Ÿæƒ…åˆ†æã®æ™‚ç³»åˆ—CSVï¼ˆä¾‹: sentiment_analysis/æ¾æœ¬äººå¿—_sentiment_1h.csvï¼‰'
    )
    parser.add_argument(
        '--stance_csv',
        required=True,
        help='ç«‹å ´åˆ†é¡ã®æ¨è«–çµæœCSVï¼ˆä¾‹: stance_results/æ¾æœ¬äººå¿—_stance.csvï¼‰'
    )
    parser.add_argument(
        '--output_csv',
        help='å‡ºåŠ›CSVãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰'
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ç‰¹å¾´é‡çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ (Feature Builder)")
    print("=" * 60)
    
    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
    script_dir = Path(__file__).parent
    os.chdir(script_dir)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not Path(args.sentiment_csv).exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: æ„Ÿæƒ…åˆ†æCSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.sentiment_csv}")
        sys.exit(1)
    
    if not Path(args.stance_csv).exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ç«‹å ´åˆ†é¡CSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.stance_csv}")
        sys.exit(1)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        sentiment_df = load_sentiment_timeseries(args.sentiment_csv)
        stance_df = load_and_aggregate_stance(args.stance_csv)
        
        # ç‰¹å¾´é‡ç”Ÿæˆ
        features_df = create_features(sentiment_df, stance_df)
        
        # çµ±è¨ˆè¡¨ç¤º
        print_statistics(features_df)
        
        # å‡ºåŠ›ãƒ‘ã‚¹æ±ºå®š
        if args.output_csv:
            output_path = args.output_csv
        else:
            # ã‚¯ã‚¨ãƒªåã‚’æŠ½å‡º
            query = extract_query_name(args.sentiment_csv)
            output_path = f"outputs/{query}/{query}_feature_table.csv"
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # CSVä¿å­˜
        print(f"\nğŸ’¾ ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä¿å­˜ä¸­: {output_path}")
        features_df.to_csv(output_path, index=False)
        print("âœ“ ä¿å­˜å®Œäº†")
        
        print("\n" + "=" * 60)
        print("âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()


# å®Ÿè¡Œä¾‹:
# python feature_builder.py \
#   --sentiment_csv ../../modules/sentiment_analysis/dictionary_based/outputs/æ¾æœ¬äººå¿—/æ¾æœ¬äººå¿—_sentiment_1h.csv \
#   --stance_csv ../../modules/stance_detection/outputs/æ¾æœ¬äººå¿—/æ¾æœ¬äººå¿—_stance.csv \
#   --output_csv outputs/æ¾æœ¬äººå¿—/æ¾æœ¬äººå¿—_feature_table.csv
