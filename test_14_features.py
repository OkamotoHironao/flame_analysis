#!/usr/bin/env python3
"""
14ç‰¹å¾´é‡ç‰ˆã®æ¤œè¨¼
topic_encodedã‚’é™¤å¤–ã—ã€sentiment/stanceç³»ã®è¿½åŠ ç‰¹å¾´ã®ã¿ä½¿ç”¨

ç›®çš„: æ±åŒ–æ€§èƒ½ã¨ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹æ¤œè¨¼
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("14ç‰¹å¾´é‡ç‰ˆã®æ¤œè¨¼å®Ÿé¨“")
print("topic_encodedã‚’é™¤å¤–ã€sentiment/stanceç³»ã®ã¿è¿½åŠ ")
print("=" * 80)

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df = pd.read_csv('outputs/unified_model_v2/combined_labeled.csv')

if 'is_controversy' in df.columns:
    df['label'] = df['is_controversy']
else:
    df['label'] = df['is_flame']

print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±")
print(f"  ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df)}ä»¶")
print(f"  ç‚ä¸Š: {(df['label']==1).sum()}ä»¶")
print(f"  éç‚ä¸Š: {(df['label']==0).sum()}ä»¶")

# ç‰¹å¾´é‡å®šç¾©
FEATURES_10 = [
    'volume', 'negative_rate', 'stance_against_rate',
    'stance_favor_rate', 'stance_neutral_rate',
    'delta_volume', 'delta_volume_rate',
    'flame_score', 'against_count', 'sentiment_polarity'
]

FEATURES_14 = FEATURES_10 + [
    'delta_negative_rate', 'delta_against_rate',
    'sentiment_avg_score',
    'stance_against_mean', 'stance_favor_mean', 'stance_neutral_mean'
]

print(f"\nğŸ“‹ ä½¿ç”¨ç‰¹å¾´é‡ ({len(FEATURES_14)}å€‹):")
print("\nã€æ—¢å­˜10ç‰¹å¾´é‡ã€‘")
for i, f in enumerate(FEATURES_10, 1):
    print(f"  {i:2d}. {f}")

print("\nã€è¿½åŠ 4ç‰¹å¾´é‡ã€‘")
for i, f in enumerate(FEATURES_14[10:], 11):
    print(f"  {i:2d}. {f}")

# =================================================================
# å®Ÿé¨“1: æ¨™æº–è©•ä¾¡ï¼ˆtrain/test splitï¼‰
# =================================================================
print("\n" + "=" * 80)
print("å®Ÿé¨“1: æ¨™æº–è©•ä¾¡ï¼ˆ80/20åˆ†å‰²ã€åŒä¸€ãƒˆãƒ”ãƒƒã‚¯å†…ã§ã®è©•ä¾¡ï¼‰")
print("=" * 80)

results_standard = {}

for name, features in [("10ç‰¹å¾´é‡", FEATURES_10), ("14ç‰¹å¾´é‡", FEATURES_14)]:
    print(f"\nğŸ¤– {name}ç‰ˆã®è©•ä¾¡")
    
    X = df[features].fillna(0).replace([np.inf, -np.inf], 0)
    y = df['label']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # CatBoost
    model = CatBoostClassifier(
        iterations=100,
        depth=5,
        learning_rate=0.1,
        random_state=42,
        verbose=0
    )
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    # CVè©•ä¾¡
    cv_scores = cross_val_score(model, X, y, cv=5, scoring='f1')
    
    results_standard[name] = {
        'accuracy': acc,
        'precision': prec,
        'recall': rec,
        'f1': f1,
        'cv_f1_mean': cv_scores.mean(),
        'cv_f1_std': cv_scores.std(),
        'feature_importance': model.feature_importances_,
        'features': features
    }
    
    print(f"  Accuracy:  {acc:.4f} ({acc*100:.2f}%)")
    print(f"  Precision: {prec:.4f} ({prec*100:.2f}%)")
    print(f"  Recall:    {rec:.4f} ({rec*100:.2f}%)")
    print(f"  F1 Score:  {f1:.4f} ({f1*100:.2f}%)")
    print(f"  CV F1:     {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")

# =================================================================
# å®Ÿé¨“2: ã‚¯ãƒ­ã‚¹ãƒˆãƒ”ãƒƒã‚¯è©•ä¾¡
# =================================================================
print("\n" + "=" * 80)
print("å®Ÿé¨“2: ã‚¯ãƒ­ã‚¹ãƒˆãƒ”ãƒƒã‚¯è©•ä¾¡ï¼ˆæœªçŸ¥ãƒˆãƒ”ãƒƒã‚¯ã§ã®æ±åŒ–æ€§èƒ½ï¼‰")
print("=" * 80)

def cross_topic_evaluation(df, features):
    """Leave-One-Topic-Out Cross Validation"""
    topics = df['topic'].unique()
    results = []
    
    for test_topic in topics:
        train_df = df[df['topic'] != test_topic]
        test_df = df[df['topic'] == test_topic]
        
        if len(test_df) < 5:
            continue
        
        X_train = train_df[features].fillna(0).replace([np.inf, -np.inf], 0)
        y_train = train_df['label']
        X_test = test_df[features].fillna(0).replace([np.inf, -np.inf], 0)
        y_test = test_df['label']
        
        model = CatBoostClassifier(
            iterations=100,
            depth=5,
            learning_rate=0.1,
            random_state=42,
            verbose=0
        )
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        f1 = f1_score(y_test, y_pred, zero_division=0)
        acc = accuracy_score(y_test, y_pred)
        
        results.append({
            'topic': test_topic,
            'n_test': len(test_df),
            'f1': f1,
            'accuracy': acc
        })
        
        print(f"  {test_topic:20s} | Test:{len(test_df):3d} | F1:{f1*100:6.2f}% | Acc:{acc*100:6.2f}%")
    
    return pd.DataFrame(results)

results_cross_topic = {}

for name, features in [("10ç‰¹å¾´é‡", FEATURES_10), ("14ç‰¹å¾´é‡", FEATURES_14)]:
    print(f"\nğŸ”„ {name}ç‰ˆã®ã‚¯ãƒ­ã‚¹ãƒˆãƒ”ãƒƒã‚¯è©•ä¾¡")
    results_df = cross_topic_evaluation(df, features)
    results_cross_topic[name] = results_df
    
    print(f"\n  å¹³å‡ F1:       {results_df['f1'].mean()*100:.2f}%")
    print(f"  F1 æ¨™æº–åå·®:   {results_df['f1'].std()*100:.2f}%")
    print(f"  å¹³å‡ Accuracy: {results_df['accuracy'].mean()*100:.2f}%")

# =================================================================
# æ¯”è¼ƒçµæœã‚µãƒãƒªãƒ¼
# =================================================================
print("\n" + "=" * 80)
print("ğŸ“Š ç·åˆæ¯”è¼ƒã‚µãƒãƒªãƒ¼")
print("=" * 80)

print("\nã€æ¨™æº–è©•ä¾¡ï¼ˆåŒä¸€ãƒˆãƒ”ãƒƒã‚¯å†…ï¼‰ã€‘")
print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
print("â”‚ æŒ‡æ¨™            â”‚ 10ç‰¹å¾´é‡     â”‚ 14ç‰¹å¾´é‡     â”‚ å·®åˆ†     â”‚")
print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
r10 = results_standard["10ç‰¹å¾´é‡"]
r14 = results_standard["14ç‰¹å¾´é‡"]
print(f"â”‚ F1 Score        â”‚ {r10['f1']*100:11.2f}% â”‚ {r14['f1']*100:11.2f}% â”‚ {(r14['f1']-r10['f1'])*100:+7.2f}% â”‚")
print(f"â”‚ Accuracy        â”‚ {r10['accuracy']*100:11.2f}% â”‚ {r14['accuracy']*100:11.2f}% â”‚ {(r14['accuracy']-r10['accuracy'])*100:+7.2f}% â”‚")
print(f"â”‚ Precision       â”‚ {r10['precision']*100:11.2f}% â”‚ {r14['precision']*100:11.2f}% â”‚ {(r14['precision']-r10['precision'])*100:+7.2f}% â”‚")
print(f"â”‚ Recall          â”‚ {r10['recall']*100:11.2f}% â”‚ {r14['recall']*100:11.2f}% â”‚ {(r14['recall']-r10['recall'])*100:+7.2f}% â”‚")
print(f"â”‚ CV F1 (å¹³å‡)    â”‚ {r10['cv_f1_mean']*100:11.2f}% â”‚ {r14['cv_f1_mean']*100:11.2f}% â”‚ {(r14['cv_f1_mean']-r10['cv_f1_mean'])*100:+7.2f}% â”‚")
print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

print("\nã€ã‚¯ãƒ­ã‚¹ãƒˆãƒ”ãƒƒã‚¯è©•ä¾¡ï¼ˆæœªçŸ¥ãƒˆãƒ”ãƒƒã‚¯ï¼‰ã€‘")
print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
print("â”‚ æŒ‡æ¨™            â”‚ 10ç‰¹å¾´é‡     â”‚ 14ç‰¹å¾´é‡     â”‚ å·®åˆ†     â”‚")
print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
c10 = results_cross_topic["10ç‰¹å¾´é‡"]
c14 = results_cross_topic["14ç‰¹å¾´é‡"]
print(f"â”‚ F1 (å¹³å‡)       â”‚ {c10['f1'].mean()*100:11.2f}% â”‚ {c14['f1'].mean()*100:11.2f}% â”‚ {(c14['f1'].mean()-c10['f1'].mean())*100:+7.2f}% â”‚")
print(f"â”‚ F1 æ¨™æº–åå·®     â”‚ {c10['f1'].std()*100:11.2f}% â”‚ {c14['f1'].std()*100:11.2f}% â”‚ {(c14['f1'].std()-c10['f1'].std())*100:+7.2f}% â”‚")
print(f"â”‚ Accuracy (å¹³å‡) â”‚ {c10['accuracy'].mean()*100:11.2f}% â”‚ {c14['accuracy'].mean()*100:11.2f}% â”‚ {(c14['accuracy'].mean()-c10['accuracy'].mean())*100:+7.2f}% â”‚")
print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

# =================================================================
# ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
# =================================================================
print("\n" + "=" * 80)
print("ğŸ” 14ç‰¹å¾´é‡ç‰ˆã®ç‰¹å¾´é‡é‡è¦åº¦ TOP10")
print("=" * 80)

importance_df = pd.DataFrame({
    'feature': FEATURES_14,
    'importance': results_standard["14ç‰¹å¾´é‡"]['feature_importance']
}).sort_values('importance', ascending=False)

print("\né †ä½ | ç‰¹å¾´é‡                    | é‡è¦åº¦")
print("â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€")
for i, row in enumerate(importance_df.head(10).itertuples(), 1):
    print(f" {i:2d}  â”‚ {row.feature:24s} â”‚ {row.importance:6.2f}")

# è¿½åŠ ç‰¹å¾´é‡ã®é‡è¦åº¦
added_features = ['delta_negative_rate', 'delta_against_rate', 
                  'sentiment_avg_score', 'stance_against_mean', 
                  'stance_favor_mean', 'stance_neutral_mean']
added_importance = importance_df[importance_df['feature'].isin(added_features)]

print("\n" + "=" * 80)
print("ğŸ“Œ è¿½åŠ 4ç‰¹å¾´é‡ã®åˆ†æ")
print("=" * 80)
print("\nç‰¹å¾´é‡                    | é‡è¦åº¦ | å…¨ä½“é †ä½")
print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€")
for row in added_importance.itertuples():
    rank = importance_df.index.get_loc(row.Index) + 1
    print(f"{row.feature:24s} â”‚ {row.importance:6.2f} â”‚ {rank:2d}ä½")

total_added = added_importance['importance'].sum()
total_all = importance_df['importance'].sum()
print(f"\nè¿½åŠ 4ç‰¹å¾´é‡ã®é‡è¦åº¦åˆè¨ˆ: {total_added:.2f} ({total_added/total_all*100:.1f}%)")

# =================================================================
# æœ€çµ‚çµè«–
# =================================================================
print("\n" + "=" * 80)
print("ğŸ’¡ æœ€çµ‚çµè«–")
print("=" * 80)

std_improvement = (r14['f1'] - r10['f1']) * 100
cross_improvement = (c14['f1'].mean() - c10['f1'].mean()) * 100

print(f"\nğŸ“Š æ€§èƒ½è©•ä¾¡:")
print(f"  æ¨™æº–è©•ä¾¡ï¼ˆåŒä¸€ãƒˆãƒ”ãƒƒã‚¯å†…ï¼‰:")
print(f"    F1ã‚¹ã‚³ã‚¢: {r10['f1']*100:.2f}% â†’ {r14['f1']*100:.2f}% ({std_improvement:+.2f}%)")
print(f"  ã‚¯ãƒ­ã‚¹ãƒˆãƒ”ãƒƒã‚¯è©•ä¾¡ï¼ˆæœªçŸ¥ãƒˆãƒ”ãƒƒã‚¯ï¼‰:")
print(f"    F1ã‚¹ã‚³ã‚¢: {c10['f1'].mean()*100:.2f}% â†’ {c14['f1'].mean()*100:.2f}% ({cross_improvement:+.2f}%)")

if std_improvement > 0.5 and cross_improvement >= -1.0:
    print(f"\nâœ… 14ç‰¹å¾´é‡ç‰ˆã‚’æ¨å¥¨")
    print(f"   ç†ç”±:")
    print(f"   - æ¨™æº–è©•ä¾¡ã§{std_improvement:+.2f}%å‘ä¸Š")
    print(f"   - ã‚¯ãƒ­ã‚¹ãƒˆãƒ”ãƒƒã‚¯è©•ä¾¡ã§{cross_improvement:+.2f}%ï¼ˆè¨±å®¹ç¯„å›²ï¼‰")
    print(f"   - sentiment_avg_score, stance_meanç³»ãŒæœ‰åŠ¹")
    print(f"   - topicã¸ã®éå­¦ç¿’ã‚’å›é¿")
    recommendation = "14ç‰¹å¾´é‡ç‰ˆ"
elif std_improvement > 0 and cross_improvement < -2.0:
    print(f"\nâš ï¸  14ç‰¹å¾´é‡ç‰ˆã¯åŠ¹æœé™å®šçš„")
    print(f"   æ¨™æº–è©•ä¾¡: {std_improvement:+.2f}%å‘ä¸Š")
    print(f"   ã‚¯ãƒ­ã‚¹ãƒˆãƒ”ãƒƒã‚¯: {cross_improvement:+.2f}%ä½ä¸‹")
    print(f"   æ±åŒ–æ€§èƒ½ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ¤œè¨")
    recommendation = "çŠ¶æ³æ¬¡ç¬¬"
else:
    print(f"\nâœ“ 10ç‰¹å¾´é‡ç‰ˆã‚’æ¨å¥¨")
    print(f"   ç†ç”±: 14ç‰¹å¾´é‡ç‰ˆã®æ”¹å–„ãŒ{std_improvement:.2f}%ã¨å°å¹…")
    print(f"   ã‚·ãƒ³ãƒ—ãƒ«ã•ã‚’å„ªå…ˆ")
    recommendation = "10ç‰¹å¾´é‡ç‰ˆ"

print(f"\nğŸ¯ æ¨å¥¨: {recommendation}")

if recommendation == "14ç‰¹å¾´é‡ç‰ˆ":
    print(f"\nğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"  1. compare_all_models.pyã‚’14ç‰¹å¾´é‡ç‰ˆã«æ›´æ–°")
    print(f"  2. 6ãƒ¢ãƒ‡ãƒ«å…¨ã¦ã§å†å®Ÿé¨“")
    print(f"  3. ãƒ—ãƒ¬ã‚¼ãƒ³è³‡æ–™ã‚’ã€Œ14ç‰¹å¾´é‡ã€ã«æ›´æ–°")
    print(f"  4. é‡è¦ç‰¹å¾´é‡TOP5ã‚’ç™ºè¡¨è³‡æ–™ã«åæ˜ ")

print("\n" + "=" * 80)
