"""
è¾æ›¸ãƒ™ãƒ¼ã‚¹ã®æ—¥æœ¬èªãƒã‚¬ãƒã‚¸åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Xã‹ã‚‰å–å¾—ã—ãŸãƒ„ã‚¤ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡ã‚’æ™‚ç³»åˆ—ã§é›†è¨ˆã™ã‚‹
"""

import pandas as pd
from pathlib import Path
import sys
import glob


def load_sentiment_dictionary(dict_path: str) -> dict:
    """
    æ¥µæ€§è¾æ›¸ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        dict_path: è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (pn_ja.csv)
        
    Returns:
        dict: {å˜èª: æ¥µæ€§å€¤} ã®è¾æ›¸
        
    Raises:
        FileNotFoundError: è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
    """
    if not Path(dict_path).exists():
        raise FileNotFoundError(f"è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {dict_path}")
    
    print(f"ğŸ“– è¾æ›¸èª­ã¿è¾¼ã¿ä¸­: {dict_path}")
    
    try:
        # è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        df_dict = pd.read_csv(dict_path)
        
        # wordåˆ—ã¨polarityåˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        if 'word' not in df_dict.columns or 'polarity' not in df_dict.columns:
            raise ValueError("è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ 'word' ã¨ 'polarity' åˆ—ãŒå¿…è¦ã§ã™")
        
        # è¾æ›¸å½¢å¼ã«å¤‰æ›
        sentiment_dict = dict(zip(df_dict['word'], df_dict['polarity']))
        
        # çµ±è¨ˆæƒ…å ±
        positive_count = sum(1 for v in sentiment_dict.values() if v > 0)
        negative_count = sum(1 for v in sentiment_dict.values() if v < 0)
        
        print(f"âœ“ è¾æ›¸èªå½™æ•°: {len(sentiment_dict)}èª")
        print(f"  - ãƒã‚¸ãƒ†ã‚£ãƒ–: {positive_count}èª")
        print(f"  - ãƒã‚¬ãƒ†ã‚£ãƒ–: {negative_count}èª")
        
        return sentiment_dict
        
    except Exception as e:
        raise ValueError(f"è¾æ›¸èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")


def calculate_sentiment_score(text: str, sentiment_dict: dict) -> int:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆè¾æ›¸ãƒ™ãƒ¼ã‚¹ãƒ»ç°¡æ˜“ç‰ˆï¼‰
    
    Args:
        text: åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
        sentiment_dict: æ¥µæ€§è¾æ›¸
        
    Returns:
        int: æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ï¼ˆè² ã®å€¤ï¼ãƒã‚¬ãƒ†ã‚£ãƒ–ã€æ­£ã®å€¤ï¼ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰
    """
    if pd.isna(text):
        return 0
    
    text = str(text)
    score = 0
    
    # è¾æ›¸å†…ã®å„å˜èªãŒãƒ†ã‚­ã‚¹ãƒˆã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    for word, polarity in sentiment_dict.items():
        if word in text:
            score += polarity
    
    return score


def analyze_sentiment(df: pd.DataFrame, sentiment_dict: dict, text_column: str = 'content') -> pd.DataFrame:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å„è¡Œã«å¯¾ã—ã¦æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œã™ã‚‹
    
    Args:
        df: åˆ†æå¯¾è±¡ã®DataFrame
        sentiment_dict: æ¥µæ€§è¾æ›¸
        text_column: ãƒ†ã‚­ã‚¹ãƒˆãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹åˆ—å
        
    Returns:
        pd.DataFrame: sentiment_score ã¨ is_negative åˆ—ãŒè¿½åŠ ã•ã‚ŒãŸDataFrame
    """
    print(f"\nğŸ“Š æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œä¸­...")
    
    # ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã®ç¢ºèª
    if text_column not in df.columns:
        # ä»£æ›¿åˆ—åã‚’æ¢ã™
        if 'text' in df.columns:
            text_column = 'text'
        elif 'content' in df.columns:
            text_column = 'content'
        else:
            raise ValueError(f"ãƒ†ã‚­ã‚¹ãƒˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆæ¢ç´¢: {text_column}, text, contentï¼‰")
    
    print(f"  ãƒ†ã‚­ã‚¹ãƒˆåˆ—: '{text_column}'")
    
    # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    df['sentiment_score'] = df[text_column].apply(
        lambda x: calculate_sentiment_score(x, sentiment_dict)
    )
    
    # ãƒã‚¬ãƒ†ã‚£ãƒ–åˆ¤å®šï¼ˆã‚¹ã‚³ã‚¢ãŒ0æœªæº€ï¼‰
    df['is_negative'] = df['sentiment_score'] < 0
    
    # çµ±è¨ˆæƒ…å ±
    total_count = len(df)
    negative_count = df['is_negative'].sum()
    negative_rate = (negative_count / total_count * 100) if total_count > 0 else 0
    avg_score = df['sentiment_score'].mean()
    
    print(f"âœ“ åˆ†æå®Œäº†:")
    print(f"  - ç·æŠ•ç¨¿æ•°: {total_count}ä»¶")
    print(f"  - ãƒã‚¬ãƒ†ã‚£ãƒ–æŠ•ç¨¿: {negative_count}ä»¶ ({negative_rate:.1f}%)")
    print(f"  - å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.2f}")
    
    return df


def aggregate_time_series_sentiment(df: pd.DataFrame, window: str = "1H") -> pd.DataFrame:
    """
    æ™‚ç³»åˆ—ã§ãƒã‚¬ãƒã‚¸åˆ†æçµæœã‚’é›†è¨ˆã™ã‚‹
    
    Args:
        df: æ„Ÿæƒ…åˆ†ææ¸ˆã¿ã®DataFrameï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯ datetimeï¼‰
        window: é›†è¨ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å¹…ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1æ™‚é–“ï¼‰
        
    Returns:
        pd.DataFrame: æ™‚ç³»åˆ—é›†è¨ˆçµæœ
    """
    print(f"\nğŸ“ˆ æ™‚ç³»åˆ—é›†è¨ˆä¸­ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: {window}ï¼‰...")
    
    # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã”ã¨ã«é›†è¨ˆ
    aggregated = df.resample(window).agg({
        'sentiment_score': ['count', 'mean'],  # æŠ•ç¨¿æ•°ã¨å¹³å‡ã‚¹ã‚³ã‚¢
        'is_negative': 'mean'  # ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡ï¼ˆTrue=1, False=0ã®å¹³å‡ï¼‰
    })
    
    # åˆ—åã‚’æ•´ç†
    aggregated.columns = ['count', 'avg_score', 'negative_rate']
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦timestampåˆ—ã«ã™ã‚‹
    aggregated = aggregated.reset_index()
    aggregated.columns = ['timestamp', 'count', 'avg_score', 'negative_rate']
    
    # çµ±è¨ˆæƒ…å ±
    print(f"âœ“ é›†è¨ˆå®Œäº†:")
    print(f"  - ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°: {len(aggregated)}")
    print(f"  - å¹³å‡æŠ•ç¨¿æ•°/ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: {aggregated['count'].mean():.2f}")
    print(f"  - å¹³å‡ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡: {aggregated['negative_rate'].mean()*100:.1f}%")
    print(f"  - æœ€å¤§ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡: {aggregated['negative_rate'].max()*100:.1f}%")
    
    return aggregated


def load_and_prepare_data(csv_path: str) -> pd.DataFrame:
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æº–å‚™ã™ã‚‹
    
    Args:
        csv_path: å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        pd.DataFrame: æ™‚ç³»åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã•ã‚ŒãŸDataFrame
        
    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        ValueError: æ—¥ä»˜å¤‰æ›ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    if not Path(csv_path).exists():
        raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
    
    print(f"\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {csv_path}")
    
    try:
        df = pd.read_csv(csv_path, comment='#')
        print(f"âœ“ {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    except Exception as e:
        raise ValueError(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # æ—¥ä»˜åˆ—ã®ç¢ºèª
    if 'created_at' in df.columns:
        date_column = 'created_at'
    elif 'date' in df.columns:
        date_column = 'date'
    else:
        raise ValueError("created_at ã¾ãŸã¯ date åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # datetimeå‹ã«å¤‰æ›
    try:
        df[date_column] = pd.to_datetime(df[date_column], utc=True)
        print(f"âœ“ æ—¥ä»˜åˆ— '{date_column}' ã‚’UTCæ™‚åˆ»ã«å¤‰æ›ã—ã¾ã—ãŸ")
    except Exception as e:
        raise ValueError(f"æ—¥ä»˜å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
    
    # æ¬ æå€¤ã‚’é™¤å»
    before_count = len(df)
    df = df.dropna(subset=[date_column])
    after_count = len(df)
    if before_count > after_count:
        print(f"âš  æ—¥ä»˜ãŒæ¬ æã—ã¦ã„ã‚‹ {before_count - after_count}ä»¶ã‚’é™¤å¤–ã—ã¾ã—ãŸ")
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¨­å®š
    df = df.set_index(date_column)
    df = df.sort_index()
    
    print(f"âœ“ æœŸé–“: {df.index.min()} ï½ {df.index.max()}")
    
    return df


def extract_query_from_filename(csv_path: str) -> str:
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æŠ½å‡ºã™ã‚‹
    
    Args:
        csv_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        str: æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆæŠ½å‡ºã§ããªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
    """
    csv_filename = Path(csv_path).stem  # æ‹¡å¼µå­ãªã—ã®ãƒ•ã‚¡ã‚¤ãƒ«å
    
    if csv_filename.startswith("tweets_"):
        # "tweets_"ã‚’é™¤å»
        name_part = csv_filename[7:]
        # æ•°å­—ã®ã¿ã®éƒ¨åˆ†ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰ã‚’é™¤å»
        parts = name_part.split("_")
        query_parts = [p for p in parts if not p.isdigit()]
        return "_".join(query_parts) if query_parts else csv_filename
    else:
        return csv_filename


def save_results(df_sentiment: pd.DataFrame, df_timeseries: pd.DataFrame, 
                output_dir: str = "sentiment_analysis", file_prefix: str = ""):
    """
    åˆ†æçµæœã‚’ä¿å­˜ã™ã‚‹
    
    Args:
        df_sentiment: æ„Ÿæƒ…åˆ†ææ¸ˆã¿ã®å…ƒãƒ‡ãƒ¼ã‚¿
        df_timeseries: æ™‚ç³»åˆ—é›†è¨ˆãƒ‡ãƒ¼ã‚¿
        output_dir: å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        file_prefix: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆæ¤œç´¢ã‚¯ã‚¨ãƒªãªã©ï¼‰
    """
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ä¸­...")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒã‚ã‚‹å ´åˆã¯ä»˜åŠ ï¼‰
    if file_prefix:
        timeseries_file = output_path / f"{file_prefix}_sentiment_1h.csv"
        sentiment_file = output_path / f"{file_prefix}_analyzed.csv"
    else:
        timeseries_file = output_path / "sentiment_1h.csv"
        sentiment_file = output_path / "analyzed.csv"
    
    # æ™‚ç³»åˆ—é›†è¨ˆçµæœã‚’ä¿å­˜
    df_timeseries.to_csv(timeseries_file, index=False)
    print(f"âœ“ æ™‚ç³»åˆ—é›†è¨ˆ: {timeseries_file}")
    
    # æ„Ÿæƒ…åˆ†ææ¸ˆã¿ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜
    df_sentiment.to_csv(sentiment_file)
    print(f"âœ“ æ„Ÿæƒ…åˆ†ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: {sentiment_file}")


def process_single_file(csv_path: str, sentiment_dict: dict, window: str, output_dir: str):
    """
    å˜ä¸€ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹
    
    Args:
        csv_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        sentiment_dict: æ¥µæ€§è¾æ›¸
        window: é›†è¨ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å¹…
        output_dir: å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æŠ½å‡º
    query = extract_query_from_filename(csv_path)
    
    print(f"\n{'='*60}")
    print(f"å‡¦ç†ä¸­: {Path(csv_path).name}")
    print(f"æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}")
    print(f"{'='*60}")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨æº–å‚™
    df = load_and_prepare_data(csv_path)
    
    # æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œ
    df_analyzed = analyze_sentiment(df, sentiment_dict)
    
    # æ™‚ç³»åˆ—é›†è¨ˆ
    df_timeseries = aggregate_time_series_sentiment(df_analyzed, window=window)
    
    # çµæœã‚’ä¿å­˜
    save_results(df_analyzed, df_timeseries, output_dir, file_prefix=query)


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    print("=" * 60)
    print("è¾æ›¸ãƒ™ãƒ¼ã‚¹ã®æ—¥æœ¬èªãƒã‚¬ãƒã‚¸åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    
    # è¨­å®š===========================================================
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰å…¥åŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—
    if len(sys.argv) > 1:
        INPUT_PATTERNS = []
        for arg in sys.argv[1:]:
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆ
            if Path(arg).is_dir():
                INPUT_PATTERNS.append(f"{arg}/**/*.csv")
            else:
                INPUT_PATTERNS.append(arg)
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        INPUT_PATTERNS = ["data/original/**/*.csv"]
    
    DICT_PATH = "data/dictionary/pn_ja.csv"
    OUTPUT_DIR = "data/processed"  # å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€
    WINDOW = "1h"  # 1æ™‚é–“ã”ã¨ã«é›†è¨ˆ
    # ===============================================================
    
    try:
        # 1. æ¥µæ€§è¾æ›¸ã‚’èª­ã¿è¾¼ã‚€ï¼ˆ1å›ã®ã¿ï¼‰
        sentiment_dict = load_sentiment_dictionary(DICT_PATH)
        
        # 2. å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
        csv_files = []
        for pattern in INPUT_PATTERNS:
            if '*' in pattern or '?' in pattern:
                # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã®å ´åˆ
                matched_files = glob.glob(pattern, recursive=True)
                csv_files.extend(matched_files)
            else:
                # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                if Path(pattern).exists():
                    csv_files.append(pattern)
        
        # é‡è¤‡ã‚’é™¤å»ã—ã¦ã‚½ãƒ¼ãƒˆ
        csv_files = sorted(set(csv_files))
        
        if not csv_files:
            print("\nâš  å‡¦ç†å¯¾è±¡ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            print(f"ãƒ‘ã‚¿ãƒ¼ãƒ³: {INPUT_PATTERNS}")
            sys.exit(0)
        
        print(f"\nğŸ“‹ å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(csv_files)}")
        for i, f in enumerate(csv_files, 1):
            print(f"  {i}. {f}")
        
        # 3. å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
        success_count = 0
        error_count = 0
        
        for csv_file in csv_files:
            try:
                process_single_file(csv_file, sentiment_dict, WINDOW, OUTPUT_DIR)
                success_count += 1
            except Exception as e:
                error_count += 1
                print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ ({Path(csv_file).name}): {e}")
                continue
        
        print("\n" + "=" * 60)
        print(f"âœ… å‡¦ç†å®Œäº†: æˆåŠŸ {success_count}ä»¶ / ã‚¨ãƒ©ãƒ¼ {error_count}ä»¶")
        print("=" * 60)
        
    except FileNotFoundError as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        sys.exit(1)
    except ValueError as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
