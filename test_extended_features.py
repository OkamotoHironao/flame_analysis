#!/usr/bin/env python3
"""
ç‰¹å¾´é‡è¿½åŠ ã®æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç¾åœ¨ã®10ç‰¹å¾´é‡ vs æ‹¡å¼µç‰ˆï¼ˆå…¨ç‰¹å¾´é‡ä½¿ç”¨ï¼‰ã§æ€§èƒ½æ¯”è¼ƒ
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
import warnings
warnings.filterwarnings('ignore')

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
print("=" * 80)
print("ç‰¹å¾´é‡è¿½åŠ æ¤œè¨¼å®Ÿé¨“")
print("=" * 80)

df = pd.read_csv('outputs/unified_model_v2/combined_labeled.csv')

# ãƒ©ãƒ™ãƒ«æº–å‚™
if 'is_controversy' in df.columns:
    df['label'] = df['is_controversy']
else:
    df['label'] = df['is_flame']

print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±")
print(f"  ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df)}ä»¶")
print(f"  ç‚ä¸Š: {(df['label']==1).sum()}ä»¶")
print(f"  éç‚ä¸Š: {(df['label']==0).sum()}ä»¶")

# ===== å®Ÿé¨“1: ç¾åœ¨ã®10ç‰¹å¾´é‡ =====
print("\n" + "=" * 80)
print("å®Ÿé¨“1: ç¾åœ¨ã®10ç‰¹å¾´é‡")
print("=" * 80)

FEATURES_CURRENT = [
    'volume', 'negative_rate', 'stance_against_rate',
    'stance_favor_rate', 'stance_neutral_rate',
    'delta_volume', 'delta_volume_rate',
    'flame_score', 'against_count', 'sentiment_polarity'
]

print(f"ä½¿ç”¨ç‰¹å¾´é‡ ({len(FEATURES_CURRENT)}å€‹):")
for i, f in enumerate(FEATURES_CURRENT, 1):
    print(f"  {i}. {f}")

X_current = df[FEATURES_CURRENT].fillna(0).replace([np.inf, -np.inf], 0)
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(
    X_current, y, test_size=0.2, random_state=42, stratify=y
)

# CatBoost (ç¾åœ¨)
print("\nğŸ¤– CatBoost (ç¾åœ¨ã®10ç‰¹å¾´é‡)")
model_current = CatBoostClassifier(
    iterations=100,
    depth=5,
    learning_rate=0.1,
    random_state=42,
    verbose=0
)
model_current.fit(X_train, y_train)
y_pred_current = model_current.predict(X_test)

acc_current = accuracy_score(y_test, y_pred_current)
prec_current = precision_score(y_test, y_pred_current)
rec_current = recall_score(y_test, y_pred_current)
f1_current = f1_score(y_test, y_pred_current)

print(f"  Accuracy:  {acc_current:.4f} ({acc_current*100:.2f}%)")
print(f"  Precision: {prec_current:.4f} ({prec_current*100:.2f}%)")
print(f"  Recall:    {rec_current:.4f} ({rec_current*100:.2f}%)")
print(f"  F1 Score:  {f1_current:.4f} ({f1_current*100:.2f}%)")

# CVè©•ä¾¡
cv_scores_current = cross_val_score(model_current, X_current, y, cv=5, scoring='f1')
print(f"  CV F1:     {cv_scores_current.mean():.4f} Â± {cv_scores_current.std():.4f}")

# ===== å®Ÿé¨“2: å…¨ç‰¹å¾´é‡ï¼ˆæ‹¡å¼µç‰ˆï¼‰=====
print("\n" + "=" * 80)
print("å®Ÿé¨“2: æ‹¡å¼µç‰ˆï¼ˆæœªä½¿ç”¨ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼‰")
print("=" * 80)

# åˆ©ç”¨å¯èƒ½ãªå…¨æ•°å€¤ç‰¹å¾´é‡
FEATURES_EXTENDED = [
    # ç¾åœ¨ä½¿ç”¨ä¸­
    'volume', 'negative_rate', 'stance_against_rate',
    'stance_favor_rate', 'stance_neutral_rate',
    'delta_volume', 'delta_volume_rate',
    'flame_score', 'against_count', 'sentiment_polarity',
    # è¿½åŠ 
    'delta_negative_rate', 'delta_against_rate',
    'sentiment_avg_score',
    'stance_against_mean', 'stance_favor_mean', 'stance_neutral_mean'
]

# topicã‚’ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¨ã—ã¦è¿½åŠ 
df_extended = df.copy()
if 'topic' in df_extended.columns:
    le = LabelEncoder()
    df_extended['topic_encoded'] = le.fit_transform(df_extended['topic'].fillna('unknown'))
    FEATURES_EXTENDED.append('topic_encoded')

print(f"ä½¿ç”¨ç‰¹å¾´é‡ ({len(FEATURES_EXTENDED)}å€‹):")
for i, f in enumerate(FEATURES_EXTENDED, 1):
    print(f"  {i}. {f}")

X_extended = df_extended[FEATURES_EXTENDED].fillna(0).replace([np.inf, -np.inf], 0)

X_train_ext, X_test_ext, y_train_ext, y_test_ext = train_test_split(
    X_extended, y, test_size=0.2, random_state=42, stratify=y
)

# CatBoost (æ‹¡å¼µç‰ˆ)
print("\nğŸ¤– CatBoost (æ‹¡å¼µç‰ˆ)")
model_extended = CatBoostClassifier(
    iterations=100,
    depth=5,
    learning_rate=0.1,
    random_state=42,
    verbose=0
)
model_extended.fit(X_train_ext, y_train_ext)
y_pred_extended = model_extended.predict(X_test_ext)

acc_extended = accuracy_score(y_test_ext, y_pred_extended)
prec_extended = precision_score(y_test_ext, y_pred_extended)
rec_extended = recall_score(y_test_ext, y_pred_extended)
f1_extended = f1_score(y_test_ext, y_pred_extended)

print(f"  Accuracy:  {acc_extended:.4f} ({acc_extended*100:.2f}%)")
print(f"  Precision: {prec_extended:.4f} ({prec_extended*100:.2f}%)")
print(f"  Recall:    {rec_extended:.4f} ({rec_extended*100:.2f}%)")
print(f"  F1 Score:  {f1_extended:.4f} ({f1_extended*100:.2f}%)")

# CVè©•ä¾¡
cv_scores_extended = cross_val_score(model_extended, X_extended, y, cv=5, scoring='f1')
print(f"  CV F1:     {cv_scores_extended.mean():.4f} Â± {cv_scores_extended.std():.4f}")

# ===== æ¯”è¼ƒçµæœ =====
print("\n" + "=" * 80)
print("ğŸ“Š æ¯”è¼ƒçµæœã‚µãƒãƒªãƒ¼")
print("=" * 80)

print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
print("â”‚ æŒ‡æ¨™            â”‚ ç¾åœ¨(10ç‰¹å¾´) â”‚ æ‹¡å¼µ(17ç‰¹å¾´) â”‚ å·®åˆ†     â”‚")
print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
print(f"â”‚ Accuracy        â”‚ {acc_current*100:11.2f}% â”‚ {acc_extended*100:11.2f}% â”‚ {(acc_extended-acc_current)*100:+7.2f}% â”‚")
print(f"â”‚ Precision       â”‚ {prec_current*100:11.2f}% â”‚ {prec_extended*100:11.2f}% â”‚ {(prec_extended-prec_current)*100:+7.2f}% â”‚")
print(f"â”‚ Recall          â”‚ {rec_current*100:11.2f}% â”‚ {rec_extended*100:11.2f}% â”‚ {(rec_extended-rec_current)*100:+7.2f}% â”‚")
print(f"â”‚ F1 Score        â”‚ {f1_current*100:11.2f}% â”‚ {f1_extended*100:11.2f}% â”‚ {(f1_extended-f1_current)*100:+7.2f}% â”‚")
print(f"â”‚ CV F1 (å¹³å‡)    â”‚ {cv_scores_current.mean()*100:11.2f}% â”‚ {cv_scores_extended.mean()*100:11.2f}% â”‚ {(cv_scores_extended.mean()-cv_scores_current.mean())*100:+7.2f}% â”‚")
print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

# ç‰¹å¾´é‡é‡è¦åº¦ã®æ¯”è¼ƒ
print("\n" + "=" * 80)
print("ğŸ” æ‹¡å¼µç‰ˆã®ç‰¹å¾´é‡é‡è¦åº¦ TOP10")
print("=" * 80)

importance_df = pd.DataFrame({
    'feature': FEATURES_EXTENDED,
    'importance': model_extended.feature_importances_
}).sort_values('importance', ascending=False)

print("\né †ä½ | ç‰¹å¾´é‡                    | é‡è¦åº¦")
print("â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€")
for i, row in enumerate(importance_df.head(10).itertuples(), 1):
    print(f" {i:2d}  â”‚ {row.feature:24s} â”‚ {row.importance:6.2f}")

# è¿½åŠ ã—ãŸç‰¹å¾´é‡ã®é‡è¦åº¦
print("\n" + "=" * 80)
print("ğŸ“Œ è¿½åŠ ç‰¹å¾´é‡ã®é‡è¦åº¦åˆ†æ")
print("=" * 80)

added_features = [
    'delta_negative_rate', 'delta_against_rate',
    'sentiment_avg_score',
    'stance_against_mean', 'stance_favor_mean', 'stance_neutral_mean',
    'topic_encoded'
]

added_importance = importance_df[importance_df['feature'].isin(added_features)]
print("\nç‰¹å¾´é‡                    | é‡è¦åº¦ | é †ä½")
print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€")
for row in added_importance.itertuples():
    rank = importance_df[importance_df['feature'] == row.feature].index[0] + 1
    print(f"{row.feature:24s} â”‚ {row.importance:6.2f} â”‚ {rank:2d}ä½")

total_added_importance = added_importance['importance'].sum()
total_importance = importance_df['importance'].sum()
print(f"\nè¿½åŠ ç‰¹å¾´é‡ã®é‡è¦åº¦åˆè¨ˆ: {total_added_importance:.2f} ({total_added_importance/total_importance*100:.1f}%)")

# ===== çµè«– =====
print("\n" + "=" * 80)
print("ğŸ’¡ çµè«–ã¨æ¨å¥¨")
print("=" * 80)

f1_improvement = (f1_extended - f1_current) * 100
cv_improvement = (cv_scores_extended.mean() - cv_scores_current.mean()) * 100

if f1_improvement > 0.5:
    print(f"\nâœ… ç‰¹å¾´é‡è¿½åŠ ã‚’æ¨å¥¨")
    print(f"   ç†ç”±: F1ã‚¹ã‚³ã‚¢ãŒ {f1_improvement:+.2f}% å‘ä¸Š")
    print(f"   CV F1ã‚‚ {cv_improvement:+.2f}% æ”¹å–„")
elif f1_improvement > 0:
    print(f"\nâš ï¸  ç‰¹å¾´é‡è¿½åŠ ã®åŠ¹æœã¯é™å®šçš„")
    print(f"   F1ã‚¹ã‚³ã‚¢å‘ä¸Š: ã‚ãšã‹ {f1_improvement:+.2f}%")
    print(f"   ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ¤œè¨")
else:
    print(f"\nâŒ ç‰¹å¾´é‡è¿½åŠ ã¯éæ¨å¥¨")
    print(f"   ç†ç”±: F1ã‚¹ã‚³ã‚¢ãŒ {f1_improvement:.2f}% ä½ä¸‹")
    print(f"   ç¾åœ¨ã®10ç‰¹å¾´é‡ã§ååˆ†")

# è¿½åŠ ç‰¹å¾´é‡ã®æœ‰ç”¨æ€§
high_importance_added = added_importance[added_importance['importance'] > 2.0]
if len(high_importance_added) > 0:
    print(f"\nğŸŒŸ ç‰¹ã«æœ‰ç”¨ãªè¿½åŠ ç‰¹å¾´é‡:")
    for row in high_importance_added.itertuples():
        print(f"   - {row.feature}: {row.importance:.2f}")
else:
    print(f"\nâš ï¸  é‡è¦åº¦2.0ä»¥ä¸Šã®è¿½åŠ ç‰¹å¾´é‡ãªã—ï¼ˆæ—¢å­˜ç‰¹å¾´é‡ã§ååˆ†ã‚«ãƒãƒ¼ï¼‰")

print("\n" + "=" * 80)
